{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUTIEPredict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRBvgLBpRgacG2cOBoK7Xu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ywsyws/CUTIE/blob/main/CUTIEPredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8FCvV-mKM-J",
        "outputId": "65eaa975-74d9-4f24-f47e-bfba20222819"
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip3 install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4so9rA1cKpoA",
        "outputId": "3ee57fc7-c72f-41b8-b008-075d9738b922"
      },
      "source": [
        "# Mount Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0XapWpKszj"
      },
      "source": [
        "# Import libraries\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior() \n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "\n",
        "import json, re, random, argparse, timeit, cv2\n",
        "from os import chdir, walk, makedirs\n",
        "from os.path import basename, split, join, exists\n",
        "from collections import defaultdict\n",
        "import unicodedata\n",
        "from pprint import pprint"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWua9ZGiKv1t"
      },
      "source": [
        "# Set root path for this project\n",
        "root_path = r'/content/gdrive/MyDrive/Colab Notebooks/CUTIE/'\n",
        "# Change working directory\n",
        "chdir(root_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE_fx8eKfOb5"
      },
      "source": [
        "# Helper functions\n",
        "\n",
        "def vis_bbox(data_loader, file_prefix, grid_table, gt_classes, model_output_val, file_name, bboxes, shape):\n",
        "    data_input_flat = grid_table.reshape([-1])\n",
        "    labels = gt_classes.reshape([-1])\n",
        "    logits = model_output_val.reshape([-1, data_loader.num_classes])\n",
        "    bboxes = bboxes.reshape([-1])\n",
        "    \n",
        "    max_len = 768*2 # upper boundary of image display size \n",
        "    img = cv2.imread(join(file_prefix, file_name))\n",
        "    if img is not None:    \n",
        "        shape = list(img.shape)\n",
        "        \n",
        "        bbox_pad = 1\n",
        "        gt_color = [[255, 250, 240], [152, 245, 255], [119,204,119], [100, 149, 237], \n",
        "                    [192, 255, 62], [119,119,204], [114,124,114], [240, 128, 128], [255, 105, 180]]\n",
        "        inf_color = [[255, 222, 173], [0, 255, 255], [50,219,50], [72, 61, 139], \n",
        "                     [154, 205, 50], [50,50,219], [64,76,64], [255, 0, 0], [255, 20, 147]]\n",
        "        \n",
        "        font_size = 0.5\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX\n",
        "        ft_color = [50, 50, 250]\n",
        "        \n",
        "        factor = max_len / max(shape)\n",
        "        shape[0], shape[1] = [int(s*factor) for s in shape[:2]]\n",
        "        \n",
        "        img = cv2.resize(img, (shape[1], shape[0]))        \n",
        "        overlay_box = np.zeros(shape, dtype=img.dtype)\n",
        "        overlay_line = np.zeros(shape, dtype=img.dtype)\n",
        "        for i in range(len(data_input_flat)):\n",
        "            if len(bboxes[i]) > 0:\n",
        "                x,y,w,h = [int(p*factor) for p in bboxes[i]]\n",
        "            else:\n",
        "                row = i // data_loader.rows\n",
        "                col = i % data_loader.cols\n",
        "                x = shape[1] // data_loader.cols * col\n",
        "                y = shape[0] // data_loader.rows * row\n",
        "                w = shape[1] // data_loader.cols * 2\n",
        "                h = shape[0] // data_loader.cols * 2\n",
        "                \n",
        "            if data_input_flat[i] and labels[i]:\n",
        "                gt_id = labels[i]                \n",
        "                cv2.rectangle(overlay_box, (x,y), (x+w,y+h), gt_color[gt_id], -1)\n",
        "                    \n",
        "            if max(logits[i]) > c_threshold:\n",
        "                inf_id = np.argmax(logits[i])\n",
        "                if inf_id:                \n",
        "                    cv2.rectangle(overlay_line, (x+bbox_pad,y+bbox_pad), \\\n",
        "                                  (x+bbox_pad+w,y+bbox_pad+h), inf_color[inf_id], max_len//768*2)\n",
        "                \n",
        "            #text = data_loader.classes[gt_id] + '|' + data_loader.classes[inf_id]\n",
        "            #cv2.putText(img, text, (x,y), font, font_size, ft_color)  \n",
        "        \n",
        "        # legends\n",
        "        w = shape[1] // data_loader.cols * 4\n",
        "        h = shape[0] // data_loader.cols * 2\n",
        "        for i in range(1, len(data_loader.classes)):\n",
        "            row = i * 3\n",
        "            col = 0\n",
        "            x = shape[1] // data_loader.cols * col\n",
        "            y = shape[0] // data_loader.rows * row \n",
        "            cv2.rectangle(img, (x,y), (x+w,y+h), gt_color[i], -1)\n",
        "            cv2.putText(img, data_loader.classes[i], (x+w,y+h), font, 0.8, ft_color)  \n",
        "            \n",
        "            row = i * 3 + 1\n",
        "            col = 0\n",
        "            x = shape[1] // data_loader.cols * col\n",
        "            y = shape[0] // data_loader.rows * row \n",
        "            cv2.rectangle(img, (x+bbox_pad,y+bbox_pad), \\\n",
        "                          (x+bbox_pad+w,y+bbox_pad+h), inf_color[i], max_len//384)        \n",
        "        \n",
        "        alpha = 0.4\n",
        "        cv2.addWeighted(overlay_box, alpha, img, 1-alpha, 0, img)\n",
        "        cv2.addWeighted(overlay_line, 1-alpha, img, 1, 0, img)\n",
        "        cv2.imwrite('results/' + file_name[:-4]+'.png', img)        \n",
        "        cv2.imshow(\"test\", img)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "\n",
        "def cal_accuracy(c_threshold, data_loader, grid_table, gt_classes, model_output_val, label_mapids, bbox_mapids):\n",
        "    #num_tp = 0\n",
        "    #num_fn = 0\n",
        "    res = ''\n",
        "    num_correct = 0\n",
        "    num_correct_strict = 0\n",
        "    num_correct_soft = 0\n",
        "    num_all = grid_table.shape[0] * (model_output_val.shape[-1]-1)\n",
        "    for b in range(grid_table.shape[0]):\n",
        "        data_input_flat = grid_table[b,:,:,0].reshape([-1])\n",
        "        labels = gt_classes[b,:,:].reshape([-1])\n",
        "        logits = model_output_val[b,:,:,:].reshape(([-1, data_loader.num_classes]))\n",
        "        label_mapid = label_mapids[b]\n",
        "        bbox_mapid = bbox_mapids[b]\n",
        "        rows, cols = grid_table.shape[1:3]\n",
        "        bbox_id = np.array([row*cols+col for row in range(rows) for col in range(cols)])\n",
        "        \n",
        "        # ignore inputs that are not word\n",
        "        indexes = np.where(data_input_flat != 0)[0]\n",
        "        print(f'len(data_input_flat): {len(data_input_flat)}')\n",
        "        print(f'indexes: {indexes}')\n",
        "        data_selected = data_input_flat[indexes]\n",
        "        labels_selected = labels[indexes]\n",
        "        logits_array_selected = logits[indexes]\n",
        "        bbox_id_selected = bbox_id[indexes]\n",
        "        \n",
        "        # calculate accuracy\n",
        "        #test_classes = [1,2,3,4,5]\n",
        "        #for c in test_classes:\n",
        "        for c in range(1, data_loader.num_classes):\n",
        "            labels_indexes = np.where(labels_selected == c)[0]\n",
        "            logits_indexes = np.where(logits_array_selected[:,c] > c_threshold)[0]\n",
        "            \n",
        "            labels_words = list(data_loader.index_to_word[i] for i in data_selected[labels_indexes])\n",
        "            logits_words = list(data_loader.index_to_word[i] for i in data_selected[logits_indexes])\n",
        "            \n",
        "            label_bbox_ids = label_mapid[c] # GT bbox_ids related to the type of class\n",
        "            logit_bbox_ids = [bbox_mapid[bbox] for bbox in bbox_id_selected[logits_indexes] if bbox in bbox_mapid]            \n",
        "            \n",
        "            #if np.array_equal(labels_indexes, logits_indexes):\n",
        "            if set(label_bbox_ids) == set(logit_bbox_ids): # decide as correct when all ids match\n",
        "                num_correct_strict += 1  \n",
        "                num_correct_soft += 1\n",
        "            elif set(label_bbox_ids).issubset(set(logit_bbox_ids)): # correct when gt is subset of gt\n",
        "                num_correct_soft += 1\n",
        "            try: # calculate prevalence with decimal precision\n",
        "                num_correct += np.shape(np.intersect1d(labels_indexes, logits_indexes))[0] / np.shape(labels_indexes)[0]\n",
        "            except ZeroDivisionError:\n",
        "                if np.shape(labels_indexes)[0] == 0:\n",
        "                    num_correct += 1\n",
        "                else:\n",
        "                    num_correct += 0        \n",
        "            \n",
        "            # show results without the <DontCare> class                    \n",
        "            if b==0:\n",
        "                res += '\\n{}(GT/Inf):\\t\"'.format(data_loader.classes[c])\n",
        "                \n",
        "                # ground truth label\n",
        "                res += ' '.join(data_loader.index_to_word[i] for i in data_selected[labels_indexes])\n",
        "                res += '\" | \"'\n",
        "                res += ' '.join(data_loader.index_to_word[i] for i in data_selected[logits_indexes])\n",
        "                res += '\"'\n",
        "                \n",
        "                # wrong inferences results\n",
        "                if not np.array_equal(labels_indexes, logits_indexes): \n",
        "                    res += '\\n \\t FALSES =>>'\n",
        "                    logits_flat = logits_array_selected[:,c]\n",
        "                    fault_logits_indexes = np.setdiff1d(logits_indexes, labels_indexes)\n",
        "                    for i in range(len(data_selected)):\n",
        "                        if i not in fault_logits_indexes: # only show fault_logits_indexes\n",
        "                            continue\n",
        "                        w = data_loader.index_to_word[data_selected[i]]\n",
        "                        l = data_loader.classes[labels_selected[i]]\n",
        "                        res += ' \"%s\"/%s, '%(w, l)\n",
        "                        #res += ' \"%s\"/%.2f%s, '%(w, logits_flat[i], l)\n",
        "                        \n",
        "                #print(res)\n",
        "    prevalence = num_correct / num_all\n",
        "    accuracy_strict = num_correct_strict / num_all\n",
        "    accuracy_soft = num_correct_soft / num_all\n",
        "    return prevalence, accuracy_strict, accuracy_soft, res.encode(\"utf-8\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMiXK63nMUF3"
      },
      "source": [
        "DEBUG = False # True to show grid as image \n",
        "\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass \n",
        "    return False\n",
        "\n",
        "class DataLoader():\n",
        "    \"\"\"\n",
        "    grid tables producer\n",
        "    \"\"\"\n",
        "    def __init__(self, params, update_dict=True, load_dictionary=False, data_split=0.75):\n",
        "        self.random = False\n",
        "        self.data_laundry = False\n",
        "        self.encoding_factor = 1 # ensures the size (rows/cols) of grid table compat with the network\n",
        "        self.classes = ['O', 'TTL']\n",
        "        #self.classes = ['DontCare', 'Table'] # for table\n",
        "        #self.classes = ['DontCare', 'Column0', 'Column1', 'Column2', 'Column3', 'Column4', 'Column5'] # for column\n",
        "        #self.classes = ['DontCare', 'Column']\n",
        "        #self.classes = ['DontCare', 'VendorName', 'VendorTaxID', 'InvoiceDate', 'InvoiceNumber', 'ExpenseAmount', 'BaseAmount', 'TaxAmount', 'TaxRate'] # for Spanish project\n",
        "        \n",
        "        self.doc_path = params.doc_path\n",
        "        self.doc_test_path = params.test_path\n",
        "        self.use_cutie2 = params.use_cutie2 \n",
        "        self.text_case = params.text_case \n",
        "        self.tokenize = params.tokenize\n",
        "        if self.tokenize:\n",
        "            self.tokenizer = tokenization.FullTokenizer('dict/vocab.txt', do_lower_case=not self.text_case)\n",
        "        \n",
        "        self.rows = self.encoding_factor # to be updated \n",
        "        self.cols = self.encoding_factor # to be updated \n",
        "        self.segment_grid = params.segment_grid if hasattr(params, 'segment_grid') else False # segment grid into two parts if grid is larger than cols_target\n",
        "        self.augment_strategy = params.augment_strategy if hasattr(params, 'augment_strategy') else 1 \n",
        "        self.pm_strategy = params.positional_mapping_strategy if hasattr(params, 'positional_mapping_strategy') else 2 \n",
        "        self.rows_segment = params.rows_segment if hasattr(params, 'rows_segment') else 72 \n",
        "        self.cols_segment = params.cols_segment if hasattr(params, 'cols_segment') else 72\n",
        "        self.rows_target = params.rows_target if hasattr(params, 'rows_target') else 64 \n",
        "        self.cols_target = params.cols_target if hasattr(params, 'cols_target') else 64 \n",
        "        self.rows_ulimit = params.rows_ulimit if hasattr(params, 'rows_ulimit') else 80 # handle OOM, must be multiple of self.encoding_factor\n",
        "        self.cols_ulimit = params.cols_ulimit if hasattr(params, 'cols_ulimit') else 80 # handle OOM, must be multiple of self.encoding_factor\n",
        "                \n",
        "        self.fill_bbox = params.fill_bbox if hasattr(params, 'fill_bbox') else False # fill bbox with labels or use one single lable for the entire bbox\n",
        "        \n",
        "        self.data_augmentation_dropout = params.data_augmentation_dropout if hasattr(params, 'data_augmentation_dropout') else False # TBD: randomly dropout rows/cols\n",
        "        self.data_augmentation_extra = params.data_augmentation_extra if hasattr(params, 'data_augmentation_extra') else False # randomly expand rows/cols\n",
        "        self.da_extra_rows = params.data_augmentation_extra_rows if hasattr(params, 'data_augmentation_extra_rows') else 0 # randomly expand rows/cols\n",
        "        self.da_extra_cols = params.data_augmentation_extra_cols if hasattr(params, 'data_augmentation_extra_cols') else 0 # randomly expand rows/cols\n",
        "        \n",
        "        ## 0> parameters to be tuned\n",
        "        self.load_dictionary = load_dictionary # load dictionary from file rather than start from empty \n",
        "        self.dict_path = params.load_dict_from_path if load_dictionary else params.dict_path\n",
        "        if self.load_dictionary:\n",
        "            self.dictionary = np.load(self.dict_path + 'dictionary.npy', allow_pickle=True).item()\n",
        "            self.word_to_index = np.load(self.dict_path + 'word_to_index.npy', allow_pickle=True).item()\n",
        "            self.index_to_word = np.load(self.dict_path + 'index_to_word.npy', allow_pickle=True).item()\n",
        "            # self.dictionary = np.load(self.dict_path + '_dictionary.npy').item()\n",
        "            # self.word_to_index = np.load(self.dict_path + '_word_to_index.npy').item()\n",
        "            # self.index_to_word = np.load(self.dict_path + '_index_to_word.npy').item()\n",
        "        else:\n",
        "            self.dictionary = {'[PAD]':0, '[UNK]':0} # word/counts. to be updated in self.load_data() and self.update_docs_dictionary()\n",
        "            self.word_to_index = {}\n",
        "            self.index_to_word = {}\n",
        "\n",
        "        self.data_split = data_split # split data to training/validation, 0 for all for validation\n",
        "        self.data_mode = 2 # 0 to consider key and value as two different class, 1 the same class, 2 only value considered\n",
        "        self.remove_lowfreq_words = False # remove low frequency words when set as True\n",
        "        \n",
        "        self.num_classes = len(self.classes)\n",
        "        self.batch_size = params.batch_size if hasattr(params, 'batch_size') else 1        \n",
        "        \n",
        "        # TBD: build a special cared dictionary\n",
        "        self.special_dict = {'*', '='} # map texts to specific tokens        \n",
        "        \n",
        "        ## 1.1> load words and their location/class as training/validation docs and labels \n",
        "        self.training_doc_files = self.get_filenames(self.doc_path)\n",
        "        self.training_docs, self.training_labels = self.load_data(self.training_doc_files, update_dict=update_dict) # TBD: optimize the update dict flag\n",
        "        \n",
        "        # polish and load dictionary/word_to_index/index_to_word as file\n",
        "        self.num_words = len(self.dictionary)              \n",
        "        self.update_word_to_index()\n",
        "        self.update_docs_dictionary(self.training_docs, 3, self.remove_lowfreq_words) # remove low frequency words and add it under the <unknown> key\n",
        "        \n",
        "        # save dictionary/word_to_index/index_to_word as file\n",
        "        np.save(self.dict_path + 'dictionary.npy', self.dictionary)\n",
        "        np.save(self.dict_path + 'word_to_index.npy', self.word_to_index)\n",
        "        np.save(self.dict_path + 'index_to_word.npy', self.index_to_word)\n",
        "        np.save(self.dict_path + 'classes.npy', self.classes)\n",
        "        # sorted(self.dictionary.items(), key=lambda x:x[1], reverse=True)\n",
        "        \n",
        "        # split training / validation docs and show statistics\n",
        "        num_training = int(len(self.training_docs)*self.data_split)\n",
        "        data_to_be_fetched = [i for i in range(len(self.training_docs))]\n",
        "        selected_training_index = data_to_be_fetched[:num_training] \n",
        "        if self.random:\n",
        "            selected_training_index = random.sample(data_to_be_fetched, num_training)\n",
        "        selected_validation_index = list(set(data_to_be_fetched).difference(set(selected_training_index)))\n",
        "        self.validation_docs = [self.training_docs[x] for x in selected_validation_index]\n",
        "        self.training_docs = [self.training_docs[x] for x in selected_training_index]\n",
        "        self.validation_labels = self.training_labels\n",
        "        print('\\n\\nDATASET: %d vocabularies, %d target classes'%(len(self.dictionary), len(self.classes)))\n",
        "        print('DATASET: %d for training, %d for validation'%(len(self.training_docs), len(self.validation_docs)))\n",
        "        \n",
        "        ## 1.2> load test files\n",
        "        self.test_doc_files = self.get_filenames(params.test_path) if hasattr(params, 'test_path') else []\n",
        "        self.test_docs, self.test_labels = self.load_data(self.test_doc_files, update_dict=update_dict) # TBD: optimize the update dict flag\n",
        "        print('DATASET: %d for test from %s \\n'%(len(self.test_docs), params.test_path if hasattr(params, 'test_path') else '_'))\n",
        "        \n",
        "        self.data_shape_statistic() # show data shape static\n",
        "        if len(self.training_docs) > 0:# adapt grid table size to all training dataset docs \n",
        "            self.rows, self.cols, _, _ = self.cal_rows_cols(self.training_docs)  \n",
        "            print('\\nDATASHAPE: data set with maximum grid table of ({},{}), updated.\\n'.format(self.rows, self.cols))    \n",
        "        else:\n",
        "            self.rows, self.cols = self.rows_ulimit, self.cols_ulimit\n",
        "                \n",
        "        ## 2> call self.next_batch() outside to generate a batch of grid tables data and labels\n",
        "        self.training_data_tobe_fetched = [i for i in range(len(self.training_docs))]\n",
        "        self.validation_data_tobe_fetched = [i for i in range(len(self.validation_docs))]        \n",
        "        self.test_data_tobe_fetched = [i for i in range(len(self.test_docs))]\n",
        "        \n",
        "    \n",
        "    def update_word_to_index(self):\n",
        "        if self.load_dictionary:\n",
        "            max_index = len(self.word_to_index.keys())\n",
        "            for word in self.dictionary:\n",
        "                if word not in self.word_to_index:\n",
        "                    max_index += 1\n",
        "                    self.word_to_index[word] = max_index\n",
        "                    self.index_to_word[max_index] = word            \n",
        "        else:   \n",
        "            self.word_to_index = dict(list(zip(self.dictionary.keys(), list(range(self.num_words))))) \n",
        "            self.index_to_word = dict(list(zip(list(range(self.num_words)), self.dictionary.keys())))\n",
        "    \n",
        "    def update_docs_dictionary(self, docs, lower_limit, remove_lowfreq_words):\n",
        "        # assign docs words that appear less than @lower_limit times to word [UNK]\n",
        "        if remove_lowfreq_words: \n",
        "            for doc in docs:\n",
        "                for line in doc:\n",
        "                    [file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                        [image_w, image_h], max_row_words, max_col_words] = line \n",
        "                    if self.dictionary[dressed_text] < lower_limit:\n",
        "                        line = [file_name, '[UNK]', self.word_to_index['[UNK]'], [x_left, y_top, x_right, y_bottom], \\\n",
        "                                [image_w, image_h], max_row_words, max_col_words]\n",
        "                        self.dictionary[dressed_text] -= 1\n",
        "                        self.dictionary['[UNK]'] += 1\n",
        "    \n",
        "    def next_batch(self):\n",
        "        batch_size = self.batch_size\n",
        "        \n",
        "        while True:\n",
        "            if len(self.training_data_tobe_fetched) < batch_size:\n",
        "                self.training_data_tobe_fetched = [i for i in range(len(self.training_docs))]            \n",
        "            selected_index = random.sample(self.training_data_tobe_fetched, batch_size)\n",
        "            self.training_data_tobe_fetched = list(set(self.training_data_tobe_fetched).difference(set(selected_index)))\n",
        "    \n",
        "            training_docs = [self.training_docs[x] for x in selected_index]\n",
        "            \n",
        "            ## data augmentation in each batch if self.data_augmentation==True\n",
        "            rows, cols, pre_rows, pre_cols = self.cal_rows_cols(training_docs, extra_augmentation=self.data_augmentation_extra, dropout=self.data_augmentation_dropout)\n",
        "            if self.data_augmentation_extra:\n",
        "                print('Training grid AUGMENT size: ({},{}) from ({},{})'\\\n",
        "                      .format(rows, cols, pre_rows, pre_cols))\n",
        "                \n",
        "                \n",
        "            \n",
        "            grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, updated_cols, ps_indices_x, ps_indices_y = \\\n",
        "                self.positional_mapping(training_docs, self.training_labels, rows, cols)   \n",
        "            if updated_cols > cols:\n",
        "                print('Training grid EXPAND size: ({},{}) from ({},{})'\\\n",
        "                      .format(rows, updated_cols, rows, cols))\n",
        "                grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, _, ps_indices_x, ps_indices_y = \\\n",
        "                    self.positional_mapping(training_docs, self.training_labels, rows, updated_cols, update_col=False)  \n",
        "            \n",
        "            ## load image and generate corresponding @ps_1dindices\n",
        "            images, ps_1d_indices = [], []\n",
        "            if self.use_cutie2:\n",
        "                images, ps_1d_indices = self.positional_sampling(self.doc_path, file_names, ps_indices_x, ps_indices_y, updated_cols)   \n",
        "                #print(\"image fetched {}\".format(len(images)))          \n",
        "                if len(images) == batch_size:\n",
        "                    break\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        batch = {'grid_table': np.array(grid_table), 'gt_classes': np.array(gt_classes), \n",
        "                 'data_image': np.array(images), 'ps_1d_indices': np.array(ps_1d_indices), # @images and @ps_1d_indices are only used for CUTIEv2\n",
        "                 'bboxes': bboxes, 'label_mapids': label_mapids, 'bbox_mapids': bbox_mapids,\n",
        "                 'file_name': file_names, 'shape': [rows,cols]}\n",
        "        return batch\n",
        "    \n",
        "    def fetch_validation_data(self):\n",
        "        batch_size = 1\n",
        "        \n",
        "        while True:\n",
        "            if len(self.validation_data_tobe_fetched) == 0:\n",
        "                self.validation_data_tobe_fetched = [i for i in range(len(self.validation_docs))]            \n",
        "            selected_index = random.sample(self.validation_data_tobe_fetched, 1)\n",
        "            self.validation_data_tobe_fetched = list(set(self.validation_data_tobe_fetched).difference(set(selected_index)))\n",
        "    \n",
        "            validation_docs = [self.validation_docs[x] for x in selected_index]\n",
        "            \n",
        "            ## fixed validation shape leads to better result (to be verified)\n",
        "            real_rows, real_cols, _, _ = self.cal_rows_cols(validation_docs, extra_augmentation=False)\n",
        "            rows = max(self.rows_target, real_rows)\n",
        "            cols = max(self.rows_target, real_cols)\n",
        "            \n",
        "            grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, updated_cols, ps_indices_x, ps_indices_y = \\\n",
        "                self.positional_mapping(validation_docs, self.validation_labels, rows, cols)   \n",
        "            if updated_cols > cols:\n",
        "                print('Validation grid EXPAND size: ({},{}) from ({},{})'\\\n",
        "                      .format(rows, updated_cols, rows, cols))\n",
        "                grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, _, ps_indices_x, ps_indices_y = \\\n",
        "                    self.positional_mapping(validation_docs, self.validation_labels, rows, updated_cols, update_col=False)     \n",
        "            \n",
        "            ## load image and generate corresponding @ps_1dindices\n",
        "            images, ps_1d_indices = [], []\n",
        "            if self.use_cutie2:\n",
        "                images, ps_1d_indices = self.positional_sampling(self.doc_path, file_names, ps_indices_x, ps_indices_y, updated_cols)  \n",
        "                if len(images) == batch_size:\n",
        "                    break        \n",
        "            else:\n",
        "                break\n",
        "            \n",
        "        def build_gt_pyramid(self, gt_classes):\n",
        "            gt_classes = np.array(gt_classes)\n",
        "            \n",
        "            rate = 4 # self.pooling_factor\n",
        "            b, h, w = np.shape(gt_classes)\n",
        "            same_padding_left = (rate-w%rate)//2 if w%rate else 0\n",
        "            same_padding_right = rate-(rate-w%rate)//2 if w%rate else 0\n",
        "            same_padding_top = (rate-h%rate)//2 if h%rate else 0\n",
        "            same_padding_bottom = rate-(rate-h%rate)//2 if h%rate else 0\n",
        "            for gt_class in gt_classes:\n",
        "                pad_v =  np.pad(gt_class, ((same_padding_top, same_padding_bottom), (0,0)), 'constant', constant_values=((0,0),(0,0)))\n",
        "                pad_h =  np.pad(gt_class, ((0,0), (same_padding_left, same_padding_right)), 'constant', constant_values=((0,0),(0,0)))\n",
        "                \n",
        "                ## find mask range for each single entity\n",
        "                num_entities = np.max(gt_classes) / self.num_classes\n",
        "                entity_ranges = [[] for _ in range(0,num_entities)]\n",
        "                for i in range(1, num_entities):\n",
        "                    if i % self.num_classes: # only consider non <DontCare> classes\n",
        "                        range_y, range_x = np.where(gt_classes==i)\n",
        "                        # entity_ranges[i] = [top, left, bottom, right, height, width]\n",
        "                        entity_ranges[i] = [min(range_y), min(range_x), max(range_y), max(range_x), \n",
        "                                            max(range_y) - min(range_y), max(range_x) - min(range_x)] \n",
        "                           \n",
        "                \n",
        "        \n",
        "        batch = {'grid_table': np.array(grid_table), 'gt_classes': np.array(gt_classes), \n",
        "                 'data_image': np.array(images), 'ps_1d_indices': np.array(ps_1d_indices), # @images and @ps_1d_indices are only used for CUTIEv2\n",
        "                 'bboxes': bboxes, 'label_mapids': label_mapids, 'bbox_mapids': bbox_mapids,\n",
        "                 'file_name': file_names, 'shape': [rows,cols]}\n",
        "        return batch\n",
        "    \n",
        "    def fetch_test_data(self): \n",
        "        batch_size = 1\n",
        "        \n",
        "        while True:\n",
        "            if len(self.test_data_tobe_fetched) == 0:\n",
        "                self.test_data_tobe_fetched = [i for i in range(len(self.test_docs))]\n",
        "                return None\n",
        "                        \n",
        "            selected_index = self.test_data_tobe_fetched[0]\n",
        "            self.test_data_tobe_fetched = list(set(self.test_data_tobe_fetched).difference(set([selected_index])))\n",
        "    \n",
        "            test_docs = [self.test_docs[selected_index]]\n",
        "            \n",
        "            real_rows, real_cols, _, _ = self.cal_rows_cols(test_docs, extra_augmentation=False)\n",
        "            rows = max(self.rows_target, real_rows) # small shaped documents have better performance with shape 64\n",
        "            cols = max(self.cols_target, real_cols) # large shaped docuemnts have better performance with shape 80\n",
        "                \n",
        "            grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, updated_cols, ps_indices_x, ps_indices_y = \\\n",
        "                self.positional_mapping(test_docs, self.test_labels, rows, cols)   \n",
        "            if updated_cols > cols:\n",
        "                print('Test grid EXPAND size: ({},{}) from ({},{})'\\\n",
        "                      .format(rows, updated_cols, rows, cols))\n",
        "                grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, _, ps_indices_x, ps_indices_y = \\\n",
        "                    self.positional_mapping(test_docs, self.test_labels, rows, updated_cols, update_col=False)    \n",
        "                    \n",
        "            ## load image and generate corresponding @ps_1dindices\n",
        "            images, ps_1d_indices = [], []\n",
        "            if self.use_cutie2:\n",
        "                images, ps_1d_indices = self.positional_sampling(self.doc_test_path, file_names, ps_indices_x, ps_indices_y, updated_cols)          \n",
        "                if len(images) == batch_size:\n",
        "                    break          \n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        batch = {'grid_table': np.array(grid_table), 'gt_classes': np.array(gt_classes), \n",
        "                 'data_image': np.array(images), 'ps_1d_indices': np.array(ps_1d_indices), # @images and @ps_1d_indices are only used for CUTIEv2\n",
        "                 'bboxes': bboxes, 'label_mapids': label_mapids, 'bbox_mapids': bbox_mapids,\n",
        "                 'file_name': file_names, 'shape': [rows,cols]}\n",
        "        return batch\n",
        "    \n",
        "    def form_label_matrix(self, gt_classes, target_h, target_w):\n",
        "        \"\"\"\n",
        "        build gt_classes and gt_masks with given target featuremap shape (height, width)\n",
        "        by inspecting bboxes regions (x,y,w,h)\n",
        "        for table / row / column identity segmentation\n",
        "        \"\"\"\n",
        "        def has_entity_with_augmentation(entity_ranges, roi, use_jittering=False):                    \n",
        "            ## find mask with maximum overlap\n",
        "            max_iou = 0\n",
        "            max_idx = None\n",
        "            roi_t, roi_l, roi_b, roi_r = roi\n",
        "            roi_h = roi_b - roi_t\n",
        "            roi_w = roi_r - roi_l\n",
        "            roi_cy = roi_t + roi_h/2\n",
        "            roi_cx = roi_l + roi_w/2\n",
        "            for idx, entity in enumerate(entity_ranges):\n",
        "                if len(entity):\n",
        "                    t, l, b, r, h, w = entity\n",
        "                    if l>roi_l and r<roi_r and t>roi_t and b<roi_b: # overlap 1\n",
        "                        iou = h*w / (roi_h*roi_w)\n",
        "                    elif l<roi_l and r>roi_r and t<roi_t and b>roi_b: # overlap 2\n",
        "                        iou = roi_h*roi_w / (h*w)\n",
        "                    elif l>roi_r or t>roi_b or b<roi_t or r<roi_l: # no intersection\n",
        "                        continue\n",
        "                    else:\n",
        "                        iou = min(h*w, roi_h*roi_w) / max(h*w, roi_h*roi_w)\n",
        "                        \n",
        "                    # TBD: add jittering augmentation method  \n",
        "                    if use_jittering:\n",
        "                        pass                          \n",
        "                    if iou > max_iou:\n",
        "                        max_idx = idx\n",
        "                        max_iou = iou\n",
        "                        \n",
        "            ## check centrality / containment / uniqueness\n",
        "            t, l, b, r, h, w = entity[idx]\n",
        "            cy = t + h/2\n",
        "            cx = l + w/2\n",
        "            if roi_t+h/3 < cy and cy < toi_b-h/3 and roi_l+w/3 < cx and cx < roi_r-w/3: # centrality\n",
        "                if (w > h and roi_w > w*0.9) or (w < h and roi_h > h*0.9): # containment\n",
        "                    if True: # uniqueness is already checked with maixmum IOU\n",
        "                        return True\n",
        "            return False                 \n",
        "    \n",
        "        shape = gt_classes.shape\n",
        "        rate_v = shape[0] / target_h\n",
        "        rate_h = shape[1] / target_w\n",
        "        dst_classes = [[[] for i in range(target_h)] for j in range(target_w)]\n",
        "        dst_masks = [[[] for i in range(target_h)] for j in range(target_w)]\n",
        "        for i in range(target_h):\n",
        "            for j in range(target_w):\n",
        "                roi = [rate_h*j, rate_v*i, rate_h*(j+1), rate_v*(i+1)] # [top, left, bottom, right]\n",
        "                \n",
        "                dst_classes[i][j] = has_entity_with_augmentation(entity_ranges, roi, False)\n",
        "                \n",
        "                mask = gt_classes[roi[1]:roi[3], roi[0]:roi[2]]\n",
        "                dst_masks[i][j] = mask if dst_classes[i][j] else np.zeros(np.shape(mask))\n",
        "        \n",
        "        return np.array(dst_classes), np.array(dst_masks)\n",
        "        \n",
        "    def data_shape_statistic(self):        \n",
        "        def shape_statistic(docs):\n",
        "            res_all = defaultdict(int)\n",
        "            res_row = defaultdict(int)\n",
        "            res_col = defaultdict(int)\n",
        "            for doc in docs:\n",
        "                rows, cols, _, _ = self.cal_rows_cols([doc])\n",
        "                res_all[rows] += 1\n",
        "                res_all[cols] += 1\n",
        "                res_row[rows] += 1\n",
        "                res_col[cols] += 1\n",
        "            res_all = sorted(res_all.items(), key=lambda x:x[0], reverse=True)\n",
        "            res_row = sorted(res_row.items(), key=lambda x:x[0], reverse=True)\n",
        "            res_col = sorted(res_col.items(), key=lambda x:x[0], reverse=True)\n",
        "            return res_all, res_row, res_col\n",
        "    \n",
        "        tss, tss_r, tss_c = shape_statistic(self.training_docs) # training shape static\n",
        "        vss, vss_r, vss_c = shape_statistic(self.validation_docs)\n",
        "        tess, tess_r, tess_c = shape_statistic(self.test_docs)\n",
        "        print(\"Training statistic: \", tss)\n",
        "        print(\"\\t num: \", len(self.training_docs))\n",
        "        print(\"\\t rows statistic: \", tss_r)\n",
        "        print(\"\\t cols statistic: \", tss_c)\n",
        "        print(\"\\nValidation statistic: \", vss)\n",
        "        print(\"\\t num: \", len(self.validation_docs))\n",
        "        print(\"\\t rows statistic: \", vss_r)\n",
        "        print(\"\\t cols statistic: \", vss_c)\n",
        "        print(\"\\nTest statistic: \", tess)\n",
        "        print(\"\\t num: \", len(self.test_docs))\n",
        "        print(\"\\t rows statistic: \", tess_r)\n",
        "        print(\"\\t cols statistic: \", tess_c)\n",
        "        \n",
        "        ## remove data samples not matching the training principle\n",
        "        def data_laundry(docs):\n",
        "            idx = 0\n",
        "            while idx < len(docs):\n",
        "                rows, cols, _, _ = self.cal_rows_cols([docs[idx]])\n",
        "                if rows > self.rows_ulimit or cols > self.cols_ulimit:\n",
        "                    del docs[idx]\n",
        "                else:\n",
        "                    idx += 1\n",
        "        if self.data_laundry:\n",
        "            print(\"\\nRemoving grids with shape larger than ({},{}).\".format(self.rows_ulimit, self.cols_ulimit))\n",
        "            data_laundry(self.training_docs)\n",
        "            data_laundry(self.validation_docs)\n",
        "            data_laundry(self.training_docs)\n",
        "        \n",
        "            tss, tss_r, tss_c = shape_statistic(self.training_docs) # training shape static\n",
        "            vss, vss_r, vss_c = shape_statistic(self.validation_docs)\n",
        "            tess, tess_r, tess_c = shape_statistic(self.test_docs)\n",
        "            print(\"Training statistic after laundary: \", tss)\n",
        "            print(\"\\t num: \", len(self.training_docs))\n",
        "            print(\"\\t rows statistic: \", tss_r)\n",
        "            print(\"\\t cols statistic: \", tss_c)\n",
        "            print(\"Validation statistic after laundary: \", vss)\n",
        "            print(\"\\t num: \", len(self.validation_docs))\n",
        "            print(\"\\t rows statistic: \", vss_r)\n",
        "            print(\"\\t cols statistic: \", vss_c)\n",
        "            print(\"Test statistic after laundary: \", tess)\n",
        "            print(\"\\t num: \", len(self.test_docs))\n",
        "            print(\"\\t rows statistic: \", tess_r)\n",
        "            print(\"\\t cols statistic: \", tess_c)\n",
        "    \n",
        "    def positional_mapping(self, docs, labels, rows, cols):\n",
        "        \"\"\"\n",
        "        docs in format:\n",
        "        [[file_name, text, word_id, [x_left, y_top, x_right, y_bottom], [left, top, right, bottom], max_row_words, max_col_words] ]\n",
        "        return grid_tables, gird_labels, dict bboxes {file_name:[]}, file_names\n",
        "        \"\"\"\n",
        "        grid_tables = []\n",
        "        gird_labels = []\n",
        "        ps_indices_x = [] # positional sampling indices\n",
        "        ps_indices_y = [] # positional sampling indices\n",
        "        bboxes = {}\n",
        "        label_mapids = []\n",
        "        bbox_mapids = [] # [{}, ] bbox identifier, each id with one or multiple bbox/bboxes\n",
        "        file_names = []\n",
        "        for doc in docs:\n",
        "            items = []\n",
        "            cols_e = 2 * cols # use @cols_e larger than required @cols as buffer\n",
        "            grid_table = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            grid_label = np.zeros([rows, cols_e], dtype=np.int8)\n",
        "            ps_x = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            ps_y = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            bbox = [[] for c in range(cols_e) for r in range(rows)]\n",
        "            bbox_id, bbox_mapid = 0, {} # one word in one or many positions in a bbox is mapped in bbox_mapid\n",
        "            label_mapid = [[] for _ in range(self.num_classes)] # each class is connected to several bboxes (words)\n",
        "            drawing_board = np.zeros([rows, cols_e], dtype=str)\n",
        "            for item in doc:\n",
        "                file_name = item[0]\n",
        "                text = item[1]\n",
        "                word_id = item[2]\n",
        "                x_left, y_top, x_right, y_bottom = item[3][:]\n",
        "                left, top, right, bottom = item[4][:]\n",
        "                \n",
        "                dict_id = self.word_to_index[text]                \n",
        "                entity_id, class_id = self.dress_class(file_name, word_id, labels)\n",
        "                \n",
        "                bbox_id += 1\n",
        "#                 if self.fill_bbox: # TBD: overlap avoidance\n",
        "#                     top = int(rows * y_top / image_h)\n",
        "#                     bottom = int(rows * y_bottom / image_h)\n",
        "#                     left = int(cols * x_left / image_w)\n",
        "#                     right = int(cols * x_right / image_w)\n",
        "#                     grid_table[top:bottom, left:right] = dict_id  \n",
        "#                     grid_label[top:bottom, left:right] = class_id  \n",
        "#                      \n",
        "#                     label_mapid[class_id].append(bbox_id)\n",
        "#                     for row in range(top, bottom):\n",
        "#                         for col in range(left, right):\n",
        "#                             bbox_mapid[row*cols+col] = bbox_id\n",
        "#                      \n",
        "#                     for y in range(top, bottom):\n",
        "#                         for x in range(left, right):\n",
        "#                             bbox[y][x] = [x_left, y_top, x_right-x_left, y_bottom-y_top]\n",
        "                label_mapid[class_id].append(bbox_id)    \n",
        "                \n",
        "                #v_c = (y_top - top + (y_bottom-y_top)/2) / (bottom-top)\n",
        "                #h_c = (x_left - left + (x_right-x_left)/2) / (right-left)\n",
        "                #v_c = (y_top + (y_bottom-y_top)/2) / bottom\n",
        "                #h_c = (x_left + (x_right-x_left)/2) / right \n",
        "                #v_c = (y_top-top) / (bottom-top)\n",
        "                #h_c = (x_left-left) / (right-left)\n",
        "                #v_c = (y_top) / (bottom)\n",
        "                #h_c = (x_left) / (right)\n",
        "                box_y = y_top + (y_bottom-y_top)/2\n",
        "                box_x = x_left # h_l is used for image feature map positional sampling\n",
        "                v_c = (y_top - top + (y_bottom-y_top)/2) / (bottom-top)\n",
        "                h_c = (x_left - left + (x_right-x_left)/2) / (right-left) # h_c is used for sorting items\n",
        "                row = int(rows * v_c) \n",
        "                col = int(cols * h_c) \n",
        "                items.append([row, col, [box_y, box_x], [v_c, h_c], file_name, dict_id, class_id, entity_id, bbox_id, [x_left, y_top, x_right-x_left, y_bottom-y_top]])                       \n",
        "            \n",
        "            items.sort(key=lambda x: (x[0], x[3], x[5])) # sort according to row > h_c > bbox_id\n",
        "            for item in items:\n",
        "                row, col, [box_y, box_x], [v_c, h_c], file_name, dict_id, class_id, entity_id, bbox_id, box = item\n",
        "                entity_class_id = entity_id*self.num_classes + class_id\n",
        "                \n",
        "                while col < cols and grid_table[row, col] != 0:\n",
        "                    col += 1            \n",
        "                \n",
        "                # self.pm_strategy 0: skip if overlap\n",
        "                # self.pm_strategy 1: shift to find slot if overlap\n",
        "                # self.pm_strategy 2: expand grid table if overlap\n",
        "                if self.pm_strategy == 0:\n",
        "                    if col == cols:                     \n",
        "                        print('overlap in {} row {} r{}c{}!'.\n",
        "                              format(file_name, row, rows, cols))\n",
        "                        #print(grid_table[row,:])\n",
        "                        #print('overlap in {} <{}> row {} r{}c{}!'.\n",
        "                        #      format(file_name, self.index_to_word[dict_id], row, rows, cols))\n",
        "                    else:\n",
        "                        grid_table[row, col] = dict_id\n",
        "                        grid_label[row, col] = entity_class_id                       \n",
        "                        bbox_mapid[row*cols+col] = bbox_id                       \n",
        "                        bbox[row*cols+col] = box   \n",
        "                elif self.pm_strategy==1 or self.pm_strategy==2:\n",
        "                    ptr = 0\n",
        "                    if col == cols: # shift to find slot to drop the current item\n",
        "                        col -= 1\n",
        "                        while ptr<cols and grid_table[row, ptr] != 0:\n",
        "                            ptr += 1\n",
        "                        if ptr == cols:\n",
        "                            grid_table[row, :-1] = grid_table[row, 1:]\n",
        "                        else:\n",
        "                            grid_table[row, ptr:-1] = grid_table[row, ptr+1:]\n",
        "                        \n",
        "                    if self.pm_strategy == 2:\n",
        "                        while col < cols_e and grid_table[row, col] != 0:\n",
        "                            col += 1\n",
        "                        if col > cols: # update maximum cols in current grid\n",
        "                            print(grid_table[row,:col])\n",
        "                            print('overlap in {} <{}> row {} r{}c{}!'.\n",
        "                                  format(file_name, self.index_to_word[dict_id], row, rows, cols))\n",
        "                            cols = col\n",
        "                        if col == cols_e:      \n",
        "                            print('overlap!')\n",
        "                    \n",
        "                    grid_table[row, col] = dict_id\n",
        "                    grid_label[row, col] = entity_class_id\n",
        "                    ps_x[row, col] = box_x\n",
        "                    ps_y[row, col] = box_y\n",
        "                    bbox_mapid[row*cols+col] = bbox_id     \n",
        "                    bbox[row*cols+col] = box\n",
        "                \n",
        "            cols = self.fit_shape(cols)\n",
        "            grid_table = grid_table[..., :cols]\n",
        "            grid_label = grid_label[..., :cols]\n",
        "            ps_x = np.array(ps_x[..., :cols])\n",
        "            ps_y = np.array(ps_y[..., :cols])\n",
        "            \n",
        "            if DEBUG:\n",
        "                self.grid_visualization(file_name, grid_table, grid_label)\n",
        "            \n",
        "            grid_tables.append(np.expand_dims(grid_table, -1)) \n",
        "            gird_labels.append(grid_label) \n",
        "            ps_indices_x.append(ps_x)\n",
        "            ps_indices_y.append(ps_y)\n",
        "            bboxes[file_name] = bbox\n",
        "            label_mapids.append(label_mapid)\n",
        "            bbox_mapids.append(bbox_mapid)\n",
        "            file_names.append(file_name)\n",
        "            \n",
        "        return grid_tables, gird_labels, bboxes, label_mapids, bbox_mapids, file_names, cols, ps_indices_x, ps_indices_y\n",
        "    \n",
        "    def positional_sampling(self, path, file_names, ps_indices_x, ps_indices_y, updated_cols):\n",
        "        images, ps_1d_indices = [], []\n",
        "        \n",
        "        ## load image and generate corresponding @ps_1dindices\n",
        "        max_h, max_w = 0, updated_cols\n",
        "        for i in range(len(file_names)):\n",
        "            file_name = file_names[i]\n",
        "            file_path = join(path, file_name) # TBD: ensure image is upright\n",
        "            ps_1d_x = np.array(ps_indices_x[i], dtype=np.float32).reshape([-1])\n",
        "            ps_1d_y = np.array(ps_indices_y[i], dtype=np.float32).reshape([-1])\n",
        "            \n",
        "            image = cv2.imread(file_path)\n",
        "            if image is not None:\n",
        "                h, w, _ = image.shape # [h,w,c]\n",
        "                factor = max_w / w\n",
        "                \n",
        "                h = int(h*factor)\n",
        "                ps_1d_x *= factor # TBD: implement more accurate mapping method rather than nearest neighbor, since the .4 or .6 leads to two different sampling results\n",
        "                ps_1d_y *= factor                \n",
        "                \n",
        "                ps_1d = np.int32(np.floor(ps_1d_x) + np.floor(ps_1d_y) * max_w)\n",
        "                max_items = max_w * h - 1\n",
        "                for i in range(len(ps_1d)):\n",
        "                    if ps_1d[i] > max_items - 1:\n",
        "                        ps_1d[i] = max_items - 1\n",
        "                    \n",
        "                \n",
        "                image = cv2.resize(image, (max_w, h))\n",
        "                image = (image-127.5) / 255\n",
        "            else:\n",
        "                #print('Warning: {} image not found!'.format(file_path))\n",
        "                print('{} ignored due to image file not found.'.format(file_path))\n",
        "                image, ps_1d = None, None\n",
        "                break\n",
        "                \n",
        "            if image is not None and ps_1d is not None: # ignore data with no images                 \n",
        "                ps_1d_indices.append(ps_1d)\n",
        "                images.append(image)\n",
        "                h,w,c = image.shape\n",
        "                if h > max_h:\n",
        "                    max_h = h\n",
        "            else:\n",
        "                pass\n",
        "                #print('{} ignored due to image file not found.'.format(file_path))\n",
        "                \n",
        "        ## pad image to the same shape\n",
        "        for i,image in enumerate(images): \n",
        "            pad_img = np.zeros([max_h, max_w, 3], dtype=image.dtype)\n",
        "            pad_img[:image.shape[0], :, :] = image\n",
        "            images[i] = pad_img\n",
        "        \n",
        "        return images, ps_1d_indices\n",
        "    \n",
        "    def load_data(self, data_files, update_dict=False):\n",
        "        \"\"\"\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        load doc words with location and class returned in format: \n",
        "        [[file_name, text, word_id, [x_left, y_top, x_right, y_bottom], [left, top, right, bottom], max_row_words, max_col_words] ]\n",
        "        \"\"\"\n",
        "        label_dressed = {}\n",
        "        doc_dressed = []\n",
        "        if not data_files:\n",
        "            print(\"no data file found.\")        \n",
        "        for file in data_files:\n",
        "            with open(file, encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                file_id = data['global_attributes']['file_id']\n",
        "                \n",
        "                label = self.collect_label(file_id, data['fileds'])\n",
        "                # ignore corrupted data\n",
        "                if not label:\n",
        "                    continue                \n",
        "                label_dressed.update(label) \n",
        "                \n",
        "                data = self.collect_data(file_id, data['text_boxes'], update_dict)\n",
        "                for i in data:\n",
        "                    doc_dressed.append(i)\n",
        "                    \n",
        "        return doc_dressed, label_dressed       \n",
        "    \n",
        "    def cal_rows_cols(self, docs, extra_augmentation=False, dropout=False):                  \n",
        "        max_row = self.encoding_factor\n",
        "        max_col = self.encoding_factor\n",
        "        for doc in docs:\n",
        "            for line in doc: \n",
        "                _, _, _, _, _, max_row_words, max_col_words = line\n",
        "                if max_row_words > max_row:\n",
        "                    max_row = max_row_words\n",
        "                if max_col_words > max_col:\n",
        "                    max_col = max_col_words\n",
        "        \n",
        "        pre_rows = self.fit_shape(max_row) #(max_row//self.encoding_factor+1) * self.encoding_factor\n",
        "        pre_cols = self.fit_shape(max_col) #(max_col//self.encoding_factor+1) * self.encoding_factor\n",
        "        \n",
        "        rows, cols = 0, 0\n",
        "        if extra_augmentation:\n",
        "            pad_row = int(random.gauss(0, self.da_extra_rows*self.encoding_factor)) #abs(random.gauss(0, u))\n",
        "            pad_col = int(random.gauss(0, self.da_extra_cols*self.encoding_factor)) #random.randint(0, u)\n",
        "            \n",
        "            if self.augment_strategy == 1: # strategy 1: augment data by increasing grid shape sizes\n",
        "                pad_row = abs(pad_row)\n",
        "                pad_col = abs(pad_col)\n",
        "                rows = self.fit_shape(max_row+pad_row) # apply upper boundary to avoid OOM\n",
        "                cols = self.fit_shape(max_col+pad_col) # apply upper boundary to avoid OOM\n",
        "            elif self.augment_strategy == 2 or self.augment_strategy == 3: # strategy 2: augment by increasing or decreasing the target gird shape size\n",
        "                rows = self.fit_shape(max(self.rows_target+pad_row, max_row)) # protect grid shape\n",
        "                cols = self.fit_shape(max(self.cols_target+pad_col, max_col)) # protect grid shape\n",
        "            else:\n",
        "                raise Exception('unknown augment strategy')\n",
        "            rows = min(rows, self.rows_ulimit) # apply upper boundary to avoid OOM\n",
        "            cols = min(cols, self.cols_ulimit) # apply upper boundary to avoid OOM                                \n",
        "        else:\n",
        "            rows = pre_rows\n",
        "            cols = pre_cols\n",
        "        return rows, cols, pre_rows, pre_cols \n",
        "    \n",
        "    def fit_shape(self, shape): # modify shape size to fit the encoding factor\n",
        "        while shape % self.encoding_factor:\n",
        "            shape += 1\n",
        "        return shape\n",
        "    \n",
        "    def expand_shape(self, shape): # expand shape size with step 2\n",
        "        return self.fit_shape(shape+1)\n",
        "        \n",
        "    def collect_data(self, file_name, content, update_dict):\n",
        "        \"\"\"\n",
        "        dress and preserve only interested data.\n",
        "        \"\"\"          \n",
        "        content_dressed = []\n",
        "        left, top, right, bottom, buffer = 9999, 9999, 0, 0, 2\n",
        "        for line in content:\n",
        "            bbox = line['bbox'] # handle data corrupt\n",
        "            if len(bbox) == 0:\n",
        "                continue\n",
        "            if line['text'] in self.special_dict: # ignore potential overlap causing characters\n",
        "                continue\n",
        "            \n",
        "            x_left, y_top, x_right, y_bottom = self.dress_bbox(bbox)        \n",
        "            # TBD: the real image size is better for calculating the relative x/y/w/h\n",
        "            if x_left < left: left = x_left - buffer\n",
        "            if y_top < top: top = y_top - buffer\n",
        "            if x_right > right: right = x_right + buffer\n",
        "            if y_bottom > bottom: bottom = y_bottom + buffer\n",
        "            \n",
        "            word_id = line['word_id']\n",
        "            dressed_texts = self._dress_text(line['text'], update_dict)\n",
        "            \n",
        "            num_block = len(dressed_texts)\n",
        "            for i, dressed_text in enumerate(dressed_texts): # handling tokenized text, separate bbox\n",
        "                new_left = int(x_left + (x_right-x_left) / num_block * (i))\n",
        "                new_right = int(x_left + (x_right-x_left) / num_block * (i+1))\n",
        "                content_dressed.append([file_name, dressed_text, word_id, [new_left, y_top, new_right, y_bottom]])\n",
        "            \n",
        "        # initial calculation of maximum number of words in rows/cols in terms of image size\n",
        "        num_words_row = [0 for _ in range(bottom)] # number of words in each row\n",
        "        num_words_col = [0 for _ in range(right)] # number of words in each column\n",
        "        for line in content_dressed:\n",
        "            _, _, _, [x_left, y_top, x_right, y_bottom] = line\n",
        "            for y in range(y_top, y_bottom):\n",
        "                num_words_row[y] += 1\n",
        "            for x in range(x_left, x_right):\n",
        "                num_words_col[x] += 1\n",
        "        max_row_words = self.fit_shape(max(num_words_row))\n",
        "        max_col_words = 0#self.fit_shape(max(num_words_col))\n",
        "        \n",
        "        # further expansion of maximum number of words in rows/cols in terms of grid shape\n",
        "        max_rows = max(self.encoding_factor, max_row_words)\n",
        "        max_cols = max(self.encoding_factor, max_col_words)\n",
        "        DONE = False\n",
        "        while not DONE:\n",
        "            DONE = True\n",
        "            grid_table = np.zeros([max_rows, max_cols], dtype=np.int32)\n",
        "            for line in content_dressed:\n",
        "                _, _, _, [x_left, y_top, x_right, y_bottom] = line\n",
        "                row = int(max_rows * (y_top - top + (y_bottom-y_top)/2) / (bottom-top))\n",
        "                col = int(max_cols * (x_left - left + (x_right-x_left)/2) / (right-left))\n",
        "                #row = int(max_rows * (y_top + (y_bottom-y_top)/2) / (bottom))\n",
        "                #col = int(max_cols * (x_left + (x_right-x_left)/2) / (right))\n",
        "                #row = int(max_rows * (y_top-top) / (bottom-top))\n",
        "                #col = int(max_cols * (x_left-left) / (right-left))\n",
        "                #row = int(max_rows * (y_top) / (bottom))\n",
        "                #col = int(max_cols * (x_left) / (right))\n",
        "                #row = int(max_rows * (y_top + (y_bottom-y_top)/2) / bottom)  \n",
        "                #col = int(max_cols * (x_left + (x_right-x_left)/2) / right) \n",
        "                \n",
        "                while col < max_cols and grid_table[row, col] != 0: # shift to find slot to drop the current item\n",
        "                    col += 1\n",
        "                if col == max_cols: # shift to find slot to drop the current item\n",
        "                    col -= 1\n",
        "                    ptr = 0\n",
        "                    while ptr<max_cols and grid_table[row, ptr] != 0:\n",
        "                        ptr += 1\n",
        "                    if ptr == max_cols: # overlap cannot be solved in current row, then expand the grid\n",
        "                        max_cols = self.expand_shape(max_cols)\n",
        "                        DONE = False\n",
        "                        break\n",
        "                    \n",
        "                    grid_table[row, ptr:-1] = grid_table[row, ptr+1:]\n",
        "                \n",
        "                if DONE:\n",
        "                    if row > max_rows or col>max_cols:\n",
        "                        print('wrong')\n",
        "                    grid_table[row, col] = 1\n",
        "        \n",
        "        max_rows = self.fit_shape(max_rows)\n",
        "        max_cols = self.fit_shape(max_cols)\n",
        "        \n",
        "        #print('{} collected in shape: {},{}'.format(file_name, max_rows, max_cols))\n",
        "        \n",
        "        # segment grid into two parts if number of cols is larger than self.cols_target\n",
        "        data = []\n",
        "        if self.segment_grid and max_cols > self.cols_segment:\n",
        "            content_dressed_left = []\n",
        "            content_dressed_right = []\n",
        "            cnt = defaultdict(int) # counter for number of words in a specific row\n",
        "            cnt_l, cnt_r = defaultdict(int), defaultdict(int) # update max_cols if larger than self.cols_segment\n",
        "            left_boundary = max_cols - self.cols_segment\n",
        "            right_boundary = self.cols_segment\n",
        "            for i, line in enumerate(content_dressed):\n",
        "                file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom] = line\n",
        "                \n",
        "                row = int(max_rows * (y_top + (y_bottom-y_top)/2) / bottom)\n",
        "                cnt[row] += 1                \n",
        "                if cnt[row] <= left_boundary:\n",
        "                    cnt_l[row] += 1\n",
        "                    content_dressed_left.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, self.cols_segment])\n",
        "                elif left_boundary < cnt[row] <= right_boundary:\n",
        "                    cnt_l[row] += 1\n",
        "                    cnt_r[row] += 1\n",
        "                    content_dressed_left.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, self.cols_segment])\n",
        "                    content_dressed_right.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max(max(cnt_r.values()), self.cols_segment)])\n",
        "                else:\n",
        "                    cnt_r[row] += 1\n",
        "                    content_dressed_right.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max(max(cnt_r.values()), self.cols_segment)])\n",
        "            #print(sorted(cnt.items(), key=lambda x:x[1], reverse=True))\n",
        "            #print(sorted(cnt_l.items(), key=lambda x:x[1], reverse=True))\n",
        "            #print(sorted(cnt_r.items(), key=lambda x:x[1], reverse=True))\n",
        "            if max(cnt_l.values()) < 2*self.cols_segment:\n",
        "                data.append(content_dressed_left)\n",
        "            if max(cnt_r.values()) < 2*self.cols_segment: # avoid OOM, which tends to happen in the right side\n",
        "                data.append(content_dressed_right)\n",
        "        else:\n",
        "            for i, line in enumerate(content_dressed): # append height/width/numofwords to the list\n",
        "                file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom] = line\n",
        "                content_dressed[i] = [file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max_cols ]\n",
        "            data.append(content_dressed)\n",
        "        return data\n",
        "    \n",
        "    def collect_label(self, file_id, content):\n",
        "        \"\"\"\n",
        "        dress and preserve only interested data.\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        \"\"\"\n",
        "        label_dressed = dict()\n",
        "        label_dressed[file_id] = {cls:[] for cls in self.classes[1:]}\n",
        "        for line in content:\n",
        "            cls = line['field_name']\n",
        "            if cls in self.classes:\n",
        "                #identity = line.get('identity', 0) \n",
        "                label_dressed[file_id][cls].append( {'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''} )\n",
        "                label_dressed[file_id][cls][-1]['key_id'] = line.get('key_id', [])\n",
        "                label_dressed[file_id][cls][-1]['value_id'] = line['value_id'] # value_id\n",
        "                label_dressed[file_id][cls][-1]['key_text'] = line.get('key_text', []) \n",
        "                label_dressed[file_id][cls][-1]['value_text'] = line['value_text'] # value_text\n",
        "                \n",
        "        # handle corrupted data\n",
        "        for cls in label_dressed[file_id]: \n",
        "            for idx, label in enumerate(label_dressed[file_id][cls]):\n",
        "                if len(label) == 0: # no relevant class in sample @file_id\n",
        "                    continue\n",
        "                if (len(label['key_text'])>0 and len(label['key_id'])==0) or \\\n",
        "                   (len(label['value_text'])>0 and len(label['value_id'])==0):\n",
        "                    return None\n",
        "            \n",
        "        return label_dressed\n",
        "\n",
        "    def dress_class(self, file_name, word_id, labels):\n",
        "        \"\"\"\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        \"\"\"\n",
        "        if file_name in labels:\n",
        "            for cls, cls_labels in labels[file_name].items():\n",
        "                for idx, cls_label in enumerate(cls_labels):\n",
        "                    for key, values in cls_label.items():\n",
        "                        if (key=='key_id' or key=='value_id') and word_id in values:\n",
        "                            if key == 'key_id':\n",
        "                                if self.data_mode == 0:\n",
        "                                    return idx, self.classes.index(cls) * 2 - 1 # odd\n",
        "                                elif self.data_mode == 1:\n",
        "                                    return idx, self.classes.index(cls)\n",
        "                                else: # ignore key_id when self.data_mode is not 0 or 1\n",
        "                                    return 0, 0\n",
        "                            elif key == 'value_id':\n",
        "                                if self.data_mode == 0:\n",
        "                                    return idx, self.classes.index(cls) * 2 # even \n",
        "                                else: # when self.data_mode is 1 or 2\n",
        "                                    return idx, self.classes.index(cls) \n",
        "            return 0, 0 # 0 is of class type 'DontCare'\n",
        "        print(\"No matched labels found for {}\".format(file_name))\n",
        "    \n",
        "    def _dress_text(self, text, update_dict):\n",
        "        \"\"\"\n",
        "        three cases covered: \n",
        "        alphabetic string, numeric string, special character\n",
        "        \"\"\"\n",
        "        string = text if self.text_case else text.lower()\n",
        "        for i, c in enumerate(string):\n",
        "            if is_number(c):\n",
        "                string = string[:i] + '0' + string[i+1:]\n",
        "                \n",
        "        strings = [string]\n",
        "        if self.tokenize:\n",
        "            strings = self.tokenizer.tokenize(strings[0])\n",
        "            #print(string, '-->', strings)\n",
        "            \n",
        "        for idx, string in enumerate(strings):            \n",
        "            if string.isalpha():\n",
        "                if string in self.special_dict:\n",
        "                    string = self.special_dict[string]\n",
        "                # TBD: convert a word to its most similar word in a known vocabulary\n",
        "            elif is_number(string):\n",
        "                pass\n",
        "            elif len(string)==1: # special character\n",
        "                pass\n",
        "            else:\n",
        "                # TBD: seperate string as parts for alpha and number combinated strings\n",
        "                #string = re.findall('[a-z]+', string)\n",
        "                pass            \n",
        "            \n",
        "            if string not in self.dictionary.keys():\n",
        "                if update_dict:\n",
        "                    self.dictionary[string] = 0\n",
        "                else:\n",
        "                    #print('unknown text: ' + string)\n",
        "                    string = '[UNK]' # TBD: take special care to unmet words\\\n",
        "            self.dictionary[string] += 1\n",
        "            \n",
        "            strings[idx] = string\n",
        "        return strings\n",
        "            \n",
        "    def dress_bbox(self, bbox):\n",
        "        positions = np.array(bbox).reshape([-1])\n",
        "        x_left = max(0, min(positions[0::2]))\n",
        "        x_right = max(positions[0::2])\n",
        "        y_top = max(0, min(positions[1::2]))\n",
        "        y_bottom = max(positions[1::2])\n",
        "        w = x_right - x_left\n",
        "        h = y_bottom - y_top\n",
        "        return int(x_left), int(y_top), int(x_right), int(y_bottom)       \n",
        "    \n",
        "    def get_filenames(self, data_path):\n",
        "        files = []\n",
        "        for dirpath,dirnames,filenames in walk(data_path):\n",
        "            for filename in filenames:\n",
        "                file = join(dirpath,filename)\n",
        "                if file.endswith('csv') or file.endswith('json'):\n",
        "                    files.append(file)\n",
        "        return files       \n",
        "            \n",
        "    # def grid_visualization(self, file_name, grid, label):\n",
        "    #     import cv2\n",
        "    #     height, width = np.shape(grid)\n",
        "    #     grid_box_h, grid_box_w = 20, 40\n",
        "    #     palette = np.zeros([height*grid_box_h, width*grid_box_w, 3], np.uint8)\n",
        "    #     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    #     gt_color = [[255, 250, 240], [152, 245, 255], [127, 255, 212], [100, 149, 237], \n",
        "    #                 [192, 255, 62], [175, 238, 238], [255, 130, 171], [240, 128, 128], [255, 105, 180]]\n",
        "    #     cv2.putText(palette, file_name+\"({},{})\".format(height,width), (grid_box_h,grid_box_w), font, 0.6, [255,0,0])  \n",
        "    #     for h in range(height):\n",
        "    #         cv2.line(palette, (0,h*grid_box_h), (width*grid_box_w, h*grid_box_h), (100,100,100))\n",
        "    #         for w in range(width):\n",
        "    #             if grid[h,w]:\n",
        "    #                 org = (int((w+1)*grid_box_w*0.7),int((h+1)*grid_box_h*0.9))\n",
        "    #                 color = gt_color[label[h,w]]\n",
        "    #                 cv2.putText(palette, self.index_to_word[grid[h,w]], org, font, 0.4, color)        \n",
        "        \n",
        "    #     img = cv2.imread(self.doc_path+'/'+file_name)\n",
        "    #     if img is not None:\n",
        "    #         shape = list(img.shape)\n",
        "    #         max_len = 768\n",
        "    #         factor = max_len / max(shape)\n",
        "    #         shape[0], shape[1] = [int(s*factor) for s in shape[:2]]\n",
        "    #         img = cv2.resize(img, (shape[1], shape[0]))  \n",
        "    #         cv2.imshow(\"img\", img)\n",
        "    #     cv2.imshow(\"grid\", palette)\n",
        "    #     cv2.waitKey(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_vW3QhxLvMS"
      },
      "source": [
        "# 1. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04fAhXgLuwf"
      },
      "source": [
        "def layer(op):\n",
        "    def layer_decorated(self, *args, **kwargs):\n",
        "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))        \n",
        "        if len(self.layer_inputs) == 0:\n",
        "            raise RuntimeError('No input variables found for layers %s' % name)\n",
        "        elif len(self.layer_inputs) == 1:\n",
        "            layer_input = self.layer_inputs[0]\n",
        "        else:\n",
        "            layer_input = list(self.layer_inputs)            \n",
        "            \n",
        "        layer_output = op(self, layer_input, *args, **kwargs)\n",
        "        \n",
        "        self.layers[name] = layer_output\n",
        "        self.feed(layer_output)\n",
        "        \n",
        "        return self\n",
        "    return layer_decorated\n",
        "    \n",
        "    \n",
        "class Model(object):\n",
        "    def __init__(self, trainable=True):\n",
        "        self.layers = dict()      \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "    \n",
        "    \n",
        "    def build_loss(self):\n",
        "        raise NotImplementedError('Must be subclassed.')\n",
        "    \n",
        "    \n",
        "    def setup(self):        \n",
        "        raise NotImplementedError('Must be subclassed.')\n",
        "     \n",
        "    \n",
        "    @layer\n",
        "    def embed(self, layer_input, vocabulary_size, embedding_size, name, dropout=1, trainable=True):\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_embedding = tf.random_uniform_initializer(-1.0, 1.0)\n",
        "            embeddings = self.make_var('weights', [vocabulary_size, embedding_size], init_embedding, None, trainable)\n",
        "            shape = tf.shape(layer_input)\n",
        "            \n",
        "            reshaped_input = tf.reshape(layer_input, [-1])\n",
        "            e = tf.nn.embedding_lookup(embeddings, reshaped_input)\n",
        "            e = tf.nn.dropout(e, dropout)\n",
        "            reshaped_e = tf.reshape(e, [shape[0], shape[1], shape[2], embedding_size])\n",
        "            return reshaped_e\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def bert_embed(self, layer_input, vocab_size, embedding_size=768, use_one_hot_embeddings=False, \n",
        "                   initializer_range=0.02, name=\"embeddings\", trainable=False):\n",
        "        with tf.compat.v1.variable_scope(\"bert\"):\n",
        "          with tf.compat.v1.variable_scope(\"embeddings\"):\n",
        "            # Perform embedding lookup on the word ids.\n",
        "            (embedding_output, embedding_table) = self.embedding_lookup(\n",
        "                input_ids=layer_input, vocab_size=vocab_size, embedding_size=embedding_size,\n",
        "                initializer_range=initializer_range,\n",
        "                word_embedding_name=\"word_embeddings\",\n",
        "                use_one_hot_embeddings=use_one_hot_embeddings,\n",
        "                trainable=trainable)\n",
        "            self.embedding_table = embedding_table # the inherited class need a self.embedding_table variable\n",
        "            return embedding_output        \n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def positional_sampling(self, layer_input, feature_dimension, name='positional_sampling'):\n",
        "        featuremap = layer_input[0]\n",
        "        batch_indices = layer_input[1]\n",
        "        grid = layer_input[2]        \n",
        "        \n",
        "        shape_grid = tf.shape(grid)\n",
        "        \n",
        "        featuremap_flat = tf.reshape(featuremap, [shape_grid[0], -1, feature_dimension])        \n",
        "        batch_indices_flat = tf.reshape(batch_indices, [shape_grid[0], -1])        \n",
        "        batch_ps_flat = tf.batch_gather(featuremap_flat, batch_indices_flat)\n",
        "        \n",
        "        b, h, w, c = shape_grid[0], shape_grid[1], shape_grid[2], feature_dimension\n",
        "        return tf.reshape(batch_ps_flat, [b,h,w,c])\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def sepconv(self, layer_input, k_h, k_w, cardinality, compression, name, activation='relu', trainable=True):\n",
        "        \"\"\" customized seperable convolution\n",
        "        \"\"\"\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
        "        activate = lambda z: tf.nn.relu(z, 'relu')\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape().as_list()[-1]\n",
        "            \n",
        "            layer_output = []\n",
        "            c = c_i / cardinality / compression\n",
        "            for _ in range(cardinality):\n",
        "                a = self.convolution(convolve, activate, layer_input, 1, 1, c_i, c,\n",
        "                                     init_weights, init_biases, regularizer, trainable, '0_{}'.format(_))                \n",
        "                a = self.convolution(convolve, activate, a, k_h, k_w, c, c, \n",
        "                                     init_weights, init_biases, regularizer, trainable, '1_{}'.format(_))\n",
        "                a = self.convolution(convolve, activate, a, 1, 1, c, c_i, \n",
        "                                     init_weights, init_biases, regularizer, trainable, '2_{}'.format(_))\n",
        "                layer_output.append(a)\n",
        "            layer_output = tf.add_n(layer_output)\n",
        "            return tf.add(layer_output, layer_input)\n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def up_sepconv(self, layer_input, k_h, k_w, cardinality, compression, name, activation='relu', trainable=True):\n",
        "        \"\"\" customized upscale seperable convolution\n",
        "        \"\"\"\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
        "        activate = lambda z: tf.nn.relu(z, 'relu')        \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            shape = tf.shape(layer_input)\n",
        "            h = shape[1]\n",
        "            w = shape[2]\n",
        "            layer_input = tf.image.resize_nearest_neighbor(layer_input, [2*h, 2*w])\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape().as_list()[-1]\n",
        "            \n",
        "            layer_output = []\n",
        "            c = c_i / cardinality / compression\n",
        "            for _ in range(cardinality):\n",
        "                a = self.convolution(convolve, activate, layer_input, 1, 1, c_i, c,\n",
        "                                     init_weights, init_biases, regularizer, trainable, '0_{}'.format(_))                \n",
        "                a = self.convolution(convolve, activate, a, k_h, k_w, c, c, \n",
        "                                     init_weights, init_biases, regularizer, trainable, '1_{}'.format(_))\n",
        "                a = self.convolution(convolve, activate, a, 1, 1, c, c_i, \n",
        "                                     init_weights, init_biases, regularizer, trainable, '2_{}'.format(_))\n",
        "                layer_output.append(a)\n",
        "            layer_output = tf.add_n(layer_output)\n",
        "            return tf.add(layer_output, layer_input)\n",
        "        \n",
        "        \n",
        "    @layer\n",
        "    def dense_block(self, layer_input, k_h, k_w, c_o, depth, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
        "        activate = lambda z: tf.nn.relu(z, 'relu')\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)  \n",
        "            \n",
        "            layer_tmp = layer_input\n",
        "            for d in range(depth):          \n",
        "                c_i = layer_tmp.get_shape()[-1]\n",
        "                a = self.convolution(convolve, activate, layer_tmp, 1, 1, c_i, c_i//2,\n",
        "                                     init_weights, init_biases, regularizer, trainable)\n",
        "                \n",
        "                a = self.convolution(convolve, activate, a, k_h, k_w, c_i, c_o, \n",
        "                                     init_weights, init_biases, regularizer, trainable)\n",
        "                \n",
        "                layer_tmp = tf.concat([a, layer_input], 3)\n",
        "                \n",
        "            return layer_tmp\n",
        "            \n",
        "        \n",
        "    @layer\n",
        "    def conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,s_h,s_w,1], 'SAME')\n",
        "        #convolve = lambda input, filter: tf.nn.atrous_conv2d(input, filter, 2, 'SAME', 'DILATE')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu') #if activation == 'relu':\n",
        "        if activation == 'sigmoid':\n",
        "            activate = lambda z: tf.nn.sigmoid(z, 'sigmoid')\n",
        "            \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "     \n",
        "     \n",
        "    @layer\n",
        "    def dilate_conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, rate, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.atrous_conv2d(input, filter, rate, 'SAME', 'DILATE')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu') #if activation == 'relu':\n",
        "        if activation == 'sigmoid':\n",
        "            activate = lambda z: tf.nn.sigmoid(z, 'sigmoid')\n",
        "            \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def dilate_module(self, layer_input, k_h, k_w, c_o, s_h, s_w, rate, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.atrous_conv2d(input, filter, rate, 'SAME', 'DILATE')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu') #if activation == 'relu':\n",
        "        if activation == 'sigmoid':\n",
        "            activate = lambda z: tf.nn.sigmoid(z, 'sigmoid')\n",
        "            \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def up_conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, name, factor=2, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,s_h,s_w,1], 'SAME')\n",
        "        #convolve = lambda input, filter: tf.nn.atrous_conv2d(input, filter, 2, 'SAME', 'DILATE')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu')        \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            shape = tf.shape(layer_input)\n",
        "            h = shape[1]\n",
        "            w = shape[2]\n",
        "            layer_input = tf.image.resize_nearest_neighbor(layer_input, [factor*h, factor*w])\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "    \n",
        "    \n",
        "    # @layer\n",
        "    # def attention(self, layer_input, num_heads, name, att_dropout=0.0, hidden_dropout=0.1, trainable=True):\n",
        "    #     \"\"\"\n",
        "    #     implement self attention with residual addition,\n",
        "    #     layer_input[0] and layer_input[1] should have the same shape for residual addition \n",
        "    #     \"\"\"\n",
        "    #     f = layer_input[0]\n",
        "    #     x = layer_input[1]\n",
        "        \n",
        "    #     convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
        "    #     with tf.variable_scope(name) as scope:\n",
        "    #         init_weights = tf.truncated_normal_initializer(0.0, 0.02)\n",
        "    #         regularizer = self.l2_regularizer(self.weight_decay)\n",
        "    #         shape = tf.shape(f)\n",
        "    #         c_i = f.get_shape()[-1]\n",
        "    #         c_o = f.get_shape()[-1]\n",
        "    #         c_a = c_o // num_heads # attention kernel depth, size per head\n",
        "            \n",
        "    #         query = self.make_var('weights_query', [1, 1, c_i, c_a], init_weights, regularizer, trainable)\n",
        "    #         query_layer = convolve(f, query) # [B, H, W, c_a]\n",
        "    #         query_layer = tf.reshape(query_layer, [shape[0], -1, c_a]) # [B, H*W, c_a]\n",
        "            \n",
        "    #         key = self.make_var('weights_key', [1, 1, c_i, c_a], init_weights, regularizer, trainable)\n",
        "    #         key_layer = convolve(f, key) # [B, H, W, c_a]\n",
        "    #         key_layer = tf.reshape(key_layer, [shape[0], -1, c_a]) # [B, H*W, c_a]\n",
        "            \n",
        "    #         value = self.make_var('weights_value', [1, 1, c_i, c_o], init_weights, regularizer, trainable)\n",
        "    #         value_layer = convolve(f, value) \n",
        "    #         value_layer = tf.reshape(value_layer, [shape[0], -1, c_o])# [B, H*W, c_o]\n",
        "            \n",
        "    #         attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True) # [B, H*W, H*W]\n",
        "    #         attention_scores = tf.multiply(attention_scores, 1.0 / math.sqrt(float(c_a.value)))\n",
        "            \n",
        "    #         attention_probs = tf.nn.softmax(attention_scores)\n",
        "    #         #attention_probs = dropout(attention_probs, att_dropout)\n",
        "            \n",
        "    #         context_layer = tf.matmul(attention_probs, value_layer) # [B, H*W, c_o]\n",
        "    #         context_layer = tf.reshape(context_layer, shape) # [B, H, W, c_o]\n",
        "            \n",
        "    #         kernel = self.make_var('output', [1, 1, c_o, c_o], init_weights, regularizer, trainable)\n",
        "    #         attention_output = convolve(context_layer, kernel) \n",
        "    #         #attention_output = dropout(attention_output, hidden_dropout)\n",
        "    #         attention_output = attention_output + x\n",
        "            \n",
        "    #         return tf.contrib.layers.instance_norm(attention_output, center=False, scale=False)\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def concat(self, layer_input, axis, name):\n",
        "        return tf.concat(layer_input, axis)\n",
        "    \n",
        "    \n",
        "    # @layer\n",
        "    # def add(self, layer_input, name):\n",
        "    #     return tf.math.add_n(layer_input)\n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def max_pool(self, layer_input, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
        "        return tf.nn.max_pool(layer_input, [1,k_h,k_w,1], [1,s_h,s_w,1], name=name, padding=padding)\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def global_pool(self, layer_input, name):\n",
        "        shape = tf.shape(layer_input)\n",
        "        h = shape[1]\n",
        "        w = shape[2]\n",
        "        output = tf.reduce_mean(layer_input, [1,2], keepdims=True, name=name)\n",
        "        return tf.image.resize_nearest_neighbor(output, [h, w])\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def softmax(self, layer_input, name):\n",
        "        return tf.nn.softmax(layer_input, name=name)      \n",
        "    \n",
        "    \n",
        "    # def embedding_lookup(self, input_ids, vocab_size, embedding_size=768,\n",
        "    #                      initializer_range=0.02, word_embedding_name=\"word_embeddings\",\n",
        "    #                      use_one_hot_embeddings=False, trainable=False):\n",
        "    #     \"\"\"Looks up words embeddings for id tensor.\n",
        "        \n",
        "    #     Args:\n",
        "    #       input_ids: int32 Tensor of shape [batch_size, seq_length] containing word\n",
        "    #         ids.\n",
        "    #       vocab_size: int. Size of the embedding vocabulary.\n",
        "    #       embedding_size: int. Width of the word embeddings.\n",
        "    #       initializer_range: float. Embedding initialization range.\n",
        "    #       word_embedding_name: string. Name of the embedding table.\n",
        "    #       use_one_hot_embeddings: bool. If True, use one-hot method for word\n",
        "    #         embeddings. If False, use `tf.nn.embedding_lookup()`. One hot is better\n",
        "    #         for TPUs.\n",
        "        \n",
        "    #     Returns:\n",
        "    #       float Tensor of shape [batch_size, seq_length, embedding_size].\n",
        "    #     \"\"\"\n",
        "    #     bert_vocab_size = 119547\n",
        "    #     # This function assumes that the input is of shape [batch_size, seq_length,\n",
        "    #     # num_inputs].\n",
        "    #     #\n",
        "    #     # If the input is a 2D tensor of shape [batch_size, seq_length], we\n",
        "    #     # reshape to [batch_size, seq_length, 1].\n",
        "    #     if input_ids.shape.ndims == 3: # originally 2\n",
        "    #         input_ids = tf.expand_dims(input_ids, axis=[-1])\n",
        "        \n",
        "    #     bert_embedding_table = embedding_table = tf.get_variable(\n",
        "    #         name=word_embedding_name,\n",
        "    #         shape=[bert_vocab_size, embedding_size],\n",
        "    #         initializer=tf.truncated_normal_initializer(stddev=initializer_range),\n",
        "    #         trainable=trainable)\n",
        "    #     if vocab_size > bert_vocab_size: # handle dict augmentation\n",
        "    #         embedding_table_plus = tf.get_variable(\n",
        "    #             name=word_embedding_name + '_plus',\n",
        "    #             shape=[vocab_size-bert_vocab_size, embedding_size],\n",
        "    #             initializer=tf.truncated_normal_initializer(stddev=initializer_range),\n",
        "    #             trainable=True)\n",
        "    #         embedding_table = tf.concat([embedding_table, embedding_table_plus], 0)        \n",
        "        \n",
        "    #     if use_one_hot_embeddings:\n",
        "    #         flat_input_ids = tf.reshape(input_ids, [-1])\n",
        "    #         one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size)\n",
        "    #         output = tf.matmul(one_hot_input_ids, embedding_table)\n",
        "    #     else:\n",
        "    #         output = tf.nn.embedding_lookup(embedding_table, input_ids)\n",
        "        \n",
        "    #     input_shape = self.get_shape_list(input_ids)\n",
        "        \n",
        "    #     output = tf.reshape(output,\n",
        "    #                         input_shape[0:-1] + [input_shape[-1] * embedding_size])\n",
        "    #     return (output, bert_embedding_table)\n",
        "    \n",
        "    # def get_shape_list(self, tensor, expected_rank=None, name=None):\n",
        "    #     \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
        "        \n",
        "    #     Args:\n",
        "    #       tensor: A tf.Tensor object to find the shape of.\n",
        "    #       expected_rank: (optional) int. The expected rank of `tensor`. If this is\n",
        "    #         specified and the `tensor` has a different rank, and exception will be\n",
        "    #         thrown.\n",
        "    #       name: Optional name of the tensor for the error message.\n",
        "        \n",
        "    #     Returns:\n",
        "    #       A list of dimensions of the shape of tensor. All static dimensions will\n",
        "    #       be returned as python integers, and dynamic dimensions will be returned\n",
        "    #       as tf.Tensor scalars.\n",
        "    #     \"\"\"\n",
        "    #     if name is None:\n",
        "    #       name = tensor.name\n",
        "        \n",
        "    #     if expected_rank is not None:\n",
        "    #       assert_rank(tensor, expected_rank, name)\n",
        "        \n",
        "    #     shape = tensor.shape.as_list()\n",
        "        \n",
        "    #     non_static_indexes = []\n",
        "    #     for (index, dim) in enumerate(shape):\n",
        "    #       if dim is None:\n",
        "    #         non_static_indexes.append(index)\n",
        "        \n",
        "    #     if not non_static_indexes:\n",
        "    #       return shape\n",
        "        \n",
        "    #     dyn_shape = tf.shape(tensor)\n",
        "    #     for index in non_static_indexes:\n",
        "    #       shape[index] = dyn_shape[index]\n",
        "    #     return shape\n",
        "    \n",
        "    \n",
        "    def convolution(self, convolve, activate, input, k_h, k_w, c_i, c_o, init_weights, init_biases, \n",
        "                    regularizer, trainable, name=''):   \n",
        "        kernel = self.make_var('weights'+name, [k_h, k_w, c_i, c_o], init_weights, regularizer, trainable) \n",
        "        biases = self.make_var('biases'+name, [c_o], init_biases, None, trainable)\n",
        "        tf.summary.histogram('w', kernel)\n",
        "        tf.summary.histogram('b', biases)\n",
        "        # test with different orders: convolve/activate/normalize; normalize/convolve/activate; convolve/normalize/activate\n",
        "        wx = convolve(input, kernel)\n",
        "        a = activate(tf.nn.bias_add(wx, biases))\n",
        "        a = tf.contrib.layers.instance_norm(a, center=False, scale=False)\n",
        "        return a\n",
        "    \n",
        "    \n",
        "    def l2_regularizer(self, weight_decay=0.0005, scope=None):\n",
        "        def regularizer(tensor):\n",
        "            with tf.name_scope(scope, default_name='l2_regularizer', values=[tensor]):\n",
        "                factor = tf.convert_to_tensor(weight_decay, name='weight_decay')\n",
        "                return tf.multiply(factor, tf.nn.l2_loss(tensor), name='decayed_value')\n",
        "        return regularizer\n",
        "    \n",
        "    \n",
        "    def make_var(self, name, shape, initializer=None, regularizer=None, trainable=True):\n",
        "        return tf.compat.v1.get_variable(name, shape, initializer=initializer, regularizer=regularizer, trainable=trainable)      \n",
        "    \n",
        "    \n",
        "    def feed(self, *args):\n",
        "        assert len(args) != 0\n",
        "        \n",
        "        self.layer_inputs = []\n",
        "        for layer in args:\n",
        "            if isinstance(layer, str):\n",
        "                try:\n",
        "                    layer = self.layers[layer]\n",
        "                    print(layer)\n",
        "                except KeyError:\n",
        "                    print(list(self.layers.keys()))\n",
        "                    raise KeyError('Unknown layer name fed: %s' % layer)\n",
        "            self.layer_inputs.append(layer)\n",
        "        return self\n",
        "        \n",
        "        \n",
        "    def get_output(self, layer):\n",
        "        try:\n",
        "            layer = self.layers[layer]\n",
        "        except KeyError:\n",
        "            print(list(self.layers.keys()))\n",
        "            raise KeyError('Unknown layer name fed: %s' % layer)\n",
        "        return layer\n",
        "        \n",
        "        \n",
        "    def get_unique_name(self, prefix):\n",
        "        id = sum(t.startswith(prefix) for t,_ in list(self.layers.items())) + 1\n",
        "        return '%s_%d' % (prefix, id)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZsXtJr-KyLu"
      },
      "source": [
        "class CUTIE(Model):\n",
        "    def __init__(self, num_vocabs, num_classes, params, trainable=True):\n",
        "        self.name = \"CUTIE_benchmark\"\n",
        "        \n",
        "        self.data = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None, 1], name='grid_table')\n",
        "        self.gt_classes = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None], name='gt_classes')\n",
        "        self.use_ghm = tf.equal(1, params.use_ghm) if hasattr(params, 'use_ghm') else tf.equal(1, 0) #params.use_ghm \n",
        "        self.activation = 'sigmoid' if (hasattr(params, 'use_ghm') and params.use_ghm) else 'relu'\n",
        "        self.ghm_weights = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, num_classes], name='ghm_weights')        \n",
        "        self.layers = dict({'data': self.data, 'gt_classes': self.gt_classes, 'ghm_weights': self.ghm_weights}) \n",
        "         \n",
        "        self.num_vocabs = num_vocabs\n",
        "        self.num_classes = num_classes     \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.embedding_size = params.embedding_size\n",
        "        self.weight_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
        "        self.hard_negative_ratio = params.hard_negative_ratio if hasattr(params, 'hard_negative_ratio') else 0.0\n",
        "        self.batch_size = params.batch_size if hasattr(params, 'batch_size') else 0\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "        \n",
        "    \n",
        "    def setup(self):        \n",
        "        # input\n",
        "        (self.feed('data')\n",
        "             .embed(self.num_vocabs, self.embedding_size, name='embedding'))  \n",
        "        \n",
        "        # encoder\n",
        "        (self.feed('embedding')\n",
        "             .conv(3, 5, 64, 1, 1, name='encoder1_1')\n",
        "             .conv(3, 5, 128, 1, 1, name='encoder1_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool1')\n",
        "             .conv(3, 5, 128, 1, 1, name='encoder2_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder2_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool2')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder3_1')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder3_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool3')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder4_1')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder4_2'))\n",
        "        \n",
        "        # decoder\n",
        "        (self.feed('encoder4_2')\n",
        "             .up_conv(3, 5, 512, 1, 1, name='up1')\n",
        "             .conv(3, 5, 256, 1, 1, name='decoder1_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='decoder1_2')\n",
        "             .up_conv(3, 5, 256, 1, 1, name='up2')\n",
        "             .conv(3, 5, 128, 1, 1, name='decoder2_1')\n",
        "             .conv(3, 5, 128, 1, 1, name='decoder2_2')\n",
        "             .up_conv(3, 5, 128, 1, 1, name='up3')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder3_1')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder3_2'))\n",
        "        \n",
        "        # classification\n",
        "        (self.feed('decoder3_2')\n",
        "             .conv(1, 1, self.num_classes, 1, 1, activation=self.activation, name='cls_logits')\n",
        "             .softmax(name='softmax'))  \n",
        "        \n",
        "    # def disp_results(self, data_input, data_label, model_output, threshold):\n",
        "    #     data_input_flat = data_input.reshape([-1]) # [b * h * w]\n",
        "    #     labels = [] # [b * h * w, classes]\n",
        "    #     for item in data_label.reshape([-1]):\n",
        "    #         labels.append([i==item for i in range(self.num_classes)])\n",
        "    #     logits = model_output.reshape([-1, self.num_classes]) # [b * h * w, classes] \n",
        "        \n",
        "    #     # ignore none word input\n",
        "    #     labels_flat = []\n",
        "    #     results_flat = []\n",
        "    #     for idx, item in enumerate(data_input_flat):\n",
        "    #         if item != 0: \n",
        "    #             labels_flat.extend(labels[idx])\n",
        "    #             results_flat.extend(logits[idx] > threshold)\n",
        "        \n",
        "    #     num_p = sum(labels_flat)\n",
        "    #     num_n = sum([1-label for label in labels_flat])   \n",
        "    #     num_all = len(results_flat)     \n",
        "    #     num_correct = sum([True for i in range(num_all) if labels_flat[i] == results_flat[i]])        \n",
        "        \n",
        "    #     labels_flat_p = [label!=0 for label in labels_flat]\n",
        "    #     labels_flat_n = [label==0 for label in labels_flat]\n",
        "    #     num_tp = sum([labels_flat_p[i] * results_flat[i] for i in range(num_all)])\n",
        "    #     num_tn = sum([labels_flat_n[i] * (not results_flat[i]) for i in range(num_all)])\n",
        "    #     num_fp = num_n - num_tp\n",
        "    #     num_fn = num_p - num_tp\n",
        "        \n",
        "    #     # accuracy, precision, recall\n",
        "    #     accuracy = num_correct / num_all\n",
        "    #     precision = num_tp / (num_tp + num_fp)\n",
        "    #     recall = num_tp / (num_tp + num_fn)\n",
        "        \n",
        "    #     return accuracy, precision, recall\n",
        "        \n",
        "        \n",
        "    # def inference(self):\n",
        "    #     return self.get_output('softmax') #cls_logits\n",
        "        \n",
        "    \n",
        "    def build_loss(self):\n",
        "        labels = self.get_output('gt_classes')\n",
        "        cls_logits = self.get_output('cls_logits')         \n",
        "        cls_logits = tf.cond(self.use_ghm, lambda: cls_logits*self.get_output('ghm_weights'), \n",
        "                             lambda: cls_logits, name=\"GradientHarmonizingMechanism\")      \n",
        "        \n",
        "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=cls_logits)\n",
        "            \n",
        "        with tf.compat.v1.variable_scope('HardNegativeMining'):\n",
        "            labels = tf.reshape(labels, [-1])  \n",
        "            cross_entropy = tf.reshape(cross_entropy, [-1])\n",
        "            \n",
        "            fg_idx = tf.where(tf.not_equal(labels, 0))\n",
        "            fgs = tf.gather(cross_entropy, fg_idx)\n",
        "            bg_idx = tf.where(tf.equal(labels, 0))\n",
        "            bgs = tf.gather(cross_entropy, bg_idx)\n",
        "             \n",
        "            num = self.hard_negative_ratio * tf.shape(fgs)[0]\n",
        "            num_bg = tf.cond(tf.shape(bgs)[0]<num, lambda:tf.shape(bgs)[0], lambda:num)\n",
        "            sorted_bgs, _ = tf.nn.top_k(tf.transpose(bgs), num_bg, sorted=True)\n",
        "            cross_entropy = fgs + sorted_bgs\n",
        "        \n",
        "        # total loss\n",
        "        model_loss = tf.reduce_mean(cross_entropy)\n",
        "        regularization_loss = tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES), name='regularization')\n",
        "        total_loss = model_loss + regularization_loss\n",
        "        \n",
        "        tf.summary.scalar('model_loss', model_loss)\n",
        "        tf.summary.scalar('regularization_loss', regularization_loss)\n",
        "        tf.summary.scalar('total_loss', total_loss)\n",
        "        \n",
        "        logits = self.get_output('cls_logits')\n",
        "        softmax_logits = self.get_output('softmax') #cls_logits\n",
        "        return model_loss, regularization_loss, total_loss, logits, softmax_logits \n",
        "    \n",
        "    # def build_multi_loss(self):\n",
        "    #     labels = self.get_output('gt_classes')\n",
        "    #     cls_logits = self.get_output('cls_logits')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGsw6HsaL2SL"
      },
      "source": [
        "class CUTIERes(CUTIE):\n",
        "    def __init__(self, num_vocabs, num_classes, params, trainable=True):\n",
        "        self.name = \"CUTIE_atrousSPP\" # \n",
        "        \n",
        "        self.data_grid = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None, 1], name='data_grid')\n",
        "        self.gt_classes = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None], name='gt_classes') \n",
        "        self.data_image = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3], name='data_image') # not used in CUTIEv1\n",
        "        self.ps_1d_indices = tf.compat.v1.placeholder(tf.int32, shape=[None, None], name='ps_1d_indices') # not used in CUTIEv1\n",
        "        \n",
        "        self.use_ghm = tf.equal(1, params.use_ghm) if hasattr(params, 'use_ghm') else tf.equal(1, 0) #params.use_ghm \n",
        "        self.activation = 'sigmoid' if (hasattr(params, 'use_ghm') and params.use_ghm) else 'relu'\n",
        "        self.dropout = params.data_augmentation_dropout if hasattr(params, 'data_augmentation_dropout') else 1\n",
        "        self.ghm_weights = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, num_classes], name='ghm_weights')        \n",
        "        self.layers = dict({'data_grid': self.data_grid, 'gt_classes': self.gt_classes, 'ghm_weights':self.ghm_weights})\n",
        "\n",
        "        self.num_vocabs = num_vocabs\n",
        "        self.num_classes = num_classes     \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.embedding_size = params.embedding_size\n",
        "        self.weight_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
        "        self.hard_negative_ratio = params.hard_negative_ratio if hasattr(params, 'hard_negative_ratio') else 0.0\n",
        "        self.batch_size = params.batch_size if hasattr(params, 'batch_size') else 0\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "        \n",
        "    \n",
        "    def setup(self):        \n",
        "        # input\n",
        "        (self.feed('data_grid')\n",
        "             .embed(self.num_vocabs, self.embedding_size, name='embedding', dropout=self.dropout))  \n",
        "        \n",
        "        # encoder\n",
        "        (self.feed('embedding')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_2')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_3')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_4')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 2, name='encoder1_5')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 4, name='encoder1_6')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 8, name='encoder1_7')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 16, name='encoder1_8'))\n",
        "        \n",
        "        # Atrous Spatial Pyramid Pooling module\n",
        "        #(self.feed('encoder1_8')\n",
        "        #     .conv(1, 1, 256, 1, 1, name='aspp_0'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 4, name='aspp_1'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 8, name='aspp_2'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 16, name='aspp_3'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .global_pool(name='aspp_4'))\n",
        "        (self.feed('aspp_1', 'aspp_2', 'aspp_3', 'aspp_4')\n",
        "             .concat(3, name='aspp_concat')\n",
        "             .conv(1, 1, 256, 1, 1, name='aspp_1x1'))\n",
        "        \n",
        "        # combine low level features\n",
        "        (self.feed('encoder1_1', 'aspp_1x1')\n",
        "             .concat(3, name='concat1')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder1_1'))\n",
        "        \n",
        "        # classification\n",
        "        (self.feed('decoder1_1') \n",
        "             .conv(1, 1, self.num_classes, 1, 1, activation=self.activation, name='cls_logits') # sigmoid for ghm\n",
        "             .softmax(name='softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xfB_lstL_nh"
      },
      "source": [
        "# 2. Predict Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kke4HoK2L4F2"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='CUTIE parameters')\n",
        "\n",
        "# Dummy parser arguments for notebook\n",
        "parser.add_argument('-f')\n",
        "\n",
        "parser.add_argument('--use_cutie2', type=bool, default=False) # True to read image from doc_path \n",
        "parser.add_argument('--is_table', type=bool, default=False) # True to read image from doc_path \n",
        "parser.add_argument('--doc_path', type=str, default='ExpressExpenseJson') # modify this\n",
        "parser.add_argument('--save_prefix', type=str, default='ExpressExpense_', help='prefix for load ckpt model') # modify this\n",
        "parser.add_argument('--test_path', type=str, default='') # leave empty if no test data provided\n",
        "\n",
        "parser.add_argument('--fill_bbox', type=bool, default=False) # augment data row/col in each batch\n",
        "\n",
        "parser.add_argument('--e_ckpt_path', type=str, default='checkpoint/') # modify this\n",
        "parser.add_argument('--ckpt_file', type=str, default='CUTIE_atrousSPP_d20000c2(r80c80)_iter_2.ckpt')\n",
        "# parser.add_argument('--e_ckpt_path', type=str, default='../graph/CUTIE/graph/') # modify this\n",
        "parser.add_argument('--positional_mapping_strategy', type=int, default=1)\n",
        "parser.add_argument('--rows_target', type=int, default=64)  # default=80\n",
        "parser.add_argument('--cols_target', type=int, default=64)  # default=80\n",
        "parser.add_argument('--rows_ulimit', type=int, default=80) \n",
        "parser.add_argument('--cols_ulimit', type=int, default=80) \n",
        "\n",
        "parser.add_argument('--load_dict', type=bool, default=True, help='True to work based on an existing dict') \n",
        "parser.add_argument('--load_dict_from_path', type=str, default='dict/') # 40000 or table or 20000TC\n",
        "parser.add_argument('--tokenize', type=bool, default=False) # tokenize input text ### default = True\n",
        "parser.add_argument('--text_case', type=bool, default=False) # case sensitive ### default = True == case sensitive\n",
        "parser.add_argument('--dict_path', type=str, default='dict/ExpressExpense') # not used if load_dict is True\n",
        "\n",
        "parser.add_argument('--restore_ckpt', type=bool, default=True) \n",
        "\n",
        "parser.add_argument('--embedding_size', type=int, default=128) \n",
        "parser.add_argument('--batch_size', type=int, default=1) \n",
        "parser.add_argument('--c_threshold', type=float, default=0.5) \n",
        "params = parser.parse_args()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh0Vu_HxMCGK",
        "outputId": "386bf4a0-0932-40c3-ca68-26cb8b50d622"
      },
      "source": [
        "# data\n",
        "#data_loader = DataLoader(params, True, True) # True to use 25% training data\n",
        "data_loader = DataLoader(params, update_dict=False, load_dictionary=True, data_split=0.75) # False to provide a path with only test data\n",
        "num_words = max(20000, data_loader.num_words)\n",
        "num_classes = data_loader.num_classes\n",
        "\n",
        "# model\n",
        "network = CUTIERes(num_words, num_classes, params)\n",
        "model_output = network.get_output('softmax')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "DATASET: 2 vocabularies, 2 target classes\n",
            "DATASET: 15 for training, 6 for validation\n",
            "no data file found.\n",
            "DATASET: 0 for test from  \n",
            "\n",
            "Training statistic:  [(32, 1), (29, 1), (28, 1), (22, 1), (20, 1), (17, 2), (15, 2), (14, 4), (12, 1), (9, 1), (8, 1), (7, 3), (6, 3), (5, 4), (3, 3), (2, 1)]\n",
            "\t num:  15\n",
            "\t rows statistic:  [(9, 1), (8, 1), (7, 3), (6, 3), (5, 4), (3, 2), (2, 1)]\n",
            "\t cols statistic:  [(32, 1), (29, 1), (28, 1), (22, 1), (20, 1), (17, 2), (15, 2), (14, 4), (12, 1), (3, 1)]\n",
            "\n",
            "Validation statistic:  [(23, 1), (18, 1), (16, 1), (14, 1), (13, 1), (9, 1), (8, 1), (7, 2), (6, 1), (4, 2)]\n",
            "\t num:  6\n",
            "\t rows statistic:  [(8, 1), (7, 2), (6, 1), (4, 2)]\n",
            "\t cols statistic:  [(23, 1), (18, 1), (16, 1), (14, 1), (13, 1), (9, 1)]\n",
            "\n",
            "Test statistic:  []\n",
            "\t num:  0\n",
            "\t rows statistic:  []\n",
            "\t cols statistic:  []\n",
            "\n",
            "DATASHAPE: data set with maximum grid table of (9,32), updated.\n",
            "\n",
            "Tensor(\"data_grid:0\", shape=(?, ?, ?, 1), dtype=int32)\n",
            "WARNING:tensorflow:From <ipython-input-6-2e1934b20eff>:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"embedding/Reshape_1:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_2/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_3/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"ResizeNearestNeighbor:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_1x1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"decoder1_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 64), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np6dshtNMEaR",
        "outputId": "a99e67e7-0966-4c06-ad46-707b14eb51ff"
      },
      "source": [
        "# evaluation\n",
        "ckpt_saver = tf.train.Saver()\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    try:\n",
        "        ckpt_path = join(params.e_ckpt_path, params.save_prefix, params.ckpt_file)\n",
        "        # ckpt_path = '/content/content/CUTIE/graph/INVOICE/CUTIE_atrousSPP_best.ckpt'\n",
        "        ckpt = tf.train.get_checkpoint_state(ckpt_path)\n",
        "        print('Restoring from {}...'.format(ckpt_path))\n",
        "        ckpt_saver.restore(sess, ckpt_path)\n",
        "        print('{} restored'.format(ckpt_path))\n",
        "    except:\n",
        "        raise Exception('Check your pretrained {:s}'.format(ckpt_path))\n",
        "    \n",
        "    # calculate validation accuracy and display results   \n",
        "    recalls, accs_strict, accs_soft = [], [], []\n",
        "    num_test = len(data_loader.validation_docs)\n",
        "    for i in range(num_test):\n",
        "        data = data_loader.fetch_validation_data()\n",
        "        print('{:d} samples left to be tested'.format(num_test-i))\n",
        "        \n",
        "#             grid_table = data['grid_table']\n",
        "#             gt_classes = data['gt_classes']\n",
        "        feed_dict = {\n",
        "            network.data_grid: data['grid_table'],\n",
        "        }\n",
        "        if params.use_cutie2:\n",
        "            feed_dict = {\n",
        "                network.data_grid: data['grid_table'],\n",
        "                network.data_image: data['data_image'],\n",
        "                network.ps_1d_indices: data['ps_1d_indices']\n",
        "            }\n",
        "        fetches = [model_output]\n",
        "        \n",
        "        print(data['file_name'][0])\n",
        "        print(data['grid_table'].shape, data['data_image'].shape, data['ps_1d_indices'].shape)\n",
        "        \n",
        "        timer_start = timeit.default_timer()\n",
        "        [model_output_val] = sess.run(fetches=fetches, feed_dict=feed_dict)\n",
        "        timer_stop = timeit.default_timer()\n",
        "        print('\\t >>time per step: %.2fs <<'%(timer_stop - timer_start))\n",
        "            \n",
        "        if not params.is_table:\n",
        "            recall, acc_strict, acc_soft, res = cal_accuracy(params.c_threshold, data_loader, np.array(data['grid_table']), \n",
        "                                                    np.array(data['gt_classes']), model_output_val, \n",
        "                                                    np.array(data['label_mapids']), data['bbox_mapids'])  \n",
        "        else:\n",
        "            recall, acc_strict, acc_soft, res = cal_accuracy_table(data_loader, np.array(data['grid_table']), \n",
        "                                                    np.array(data['gt_classes']), model_output_val, \n",
        "                                                    np.array(data['label_mapids']), data['bbox_mapids'])                     \n",
        "#             recall, acc_strict, acc_soft, res = cal_save_results(data_loader, np.array(data['grid_table']), \n",
        "#                                                        np.array(data['gt_classes']), model_output_val, \n",
        "#                                                        np.array(data['label_mapids']), data['bbox_mapids'],\n",
        "#                                                        data['file_name'][0], params.save_prefix)\n",
        "        recalls += [recall]\n",
        "        accs_strict += [acc_strict] \n",
        "        accs_soft += [acc_soft]\n",
        "        if acc_strict != 1:\n",
        "            print(res.decode()) # show res for current batch\n",
        "        \n",
        "        # visualize result\n",
        "        shape = data['shape']\n",
        "        file_name = data['file_name'][0] # use one single file_name\n",
        "        bboxes = data['bboxes'][file_name]\n",
        "        if not params.is_table:\n",
        "            vis_bbox(data_loader, params.doc_path, np.array(data['grid_table'])[0], \n",
        "                      np.array(data['gt_classes'])[0], np.array(model_output_val)[0], file_name, \n",
        "                      np.array(bboxes), shape)\n",
        "        else:\n",
        "            vis_table(data_loader, params.doc_path, np.array(data['grid_table'])[0], \n",
        "                      np.array(data['gt_classes'])[0], np.array(model_output_val)[0], file_name, \n",
        "                      np.array(bboxes), shape)\n",
        "\n",
        "    recall = sum(recalls) / len(recalls)\n",
        "    acc_strict = sum(accs_strict) / len(accs_strict)\n",
        "    acc_soft = sum(accs_soft) / len(accs_soft)\n",
        "    print('EVALUATION ACC (Recall/Acc): %.3f / %.3f (%.3f) \\n'%(recall, acc_strict, acc_soft))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restoring from checkpoint/ExpressExpense_/CUTIE_atrousSPP_d20000c2(r80c80)_iter_2.ckpt...\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/ExpressExpense_/CUTIE_atrousSPP_d20000c2(r80c80)_iter_2.ckpt\n",
            "checkpoint/ExpressExpense_/CUTIE_atrousSPP_d20000c2(r80c80)_iter_2.ckpt restored\n",
            "6 samples left to be tested\n",
            "1018-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n",
            "\t >>time per step: 1.75s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [ 117  124  206  268  300  337  344  347  356  814  818  847  859  869\n",
            "  950  957 1031 1174 1178 1183 1190 1496 1542 1554 1668 1678 1992 2044\n",
            " 2146 2183 2188 2192 2197 2203 2217 2514 2540 2745 2820 2836 2939 3017\n",
            " 3034 3127 3334 3353 3442 3451 3529 3641 3671 3752 3870 3912 4043]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "5 samples left to be tested\n",
            "1010-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t >>time per step: 1.56s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [  95  105  222  229  346  354  363  481  488  513  675  908  917  923\n",
            "  952 1079 1085 1099 1228 1235 1275 1356 1363 1367 1473 1658 1661 1677\n",
            " 1689 1698 1703 1707 1806 1815 1949 1980 1997 2006 2108 2124 2135 2250\n",
            " 2257 2266 2298 2302 2370 2394 2399 2429 2433 2442 2448 2455 2701 2748\n",
            " 2755 2877 2890 2947 3147 3196 3473 3489 3513 3808 3813 3817 3938 3946\n",
            " 4066]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "4 samples left to be tested\n",
            "1013-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n",
            "\t >>time per step: 1.56s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [  92  301  344  544  556  596  797  988 1000 1042 1196 1233 1245 1608\n",
            " 1621 1634 2042 2053 2060 2069 2250 2259 2299 2638 2732 2747 2890 2899\n",
            " 2924 2939 3084 3195 3530 3644 3975 3994]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "3 samples left to be tested\n",
            "1010-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n",
            "\t >>time per step: 1.56s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [  95  105  222  229  346  354  363  481  488  513  675  908  917  923\n",
            "  952 1079 1085 1099 1228 1235 1275 1356 1363 1367 1473 1658 1661 1677\n",
            " 1689 1698 1703 1707 1806 1815 1949 1980 1997 2006 2108 2124 2135 2250\n",
            " 2257 2266 2298 2302 2370 2394 2399 2429 2433 2442 2448 2455 2701 2748\n",
            " 2755 2877 2890 2947 3147 3196 3473 3489 3513 3808 3813 3817 3938 3946\n",
            " 4066]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "2 samples left to be tested\n",
            "1014-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n",
            "\t >>time per step: 1.54s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [  92  100  156  172  212  281  292  299  516  527  686  824  831  834\n",
            "  985 1003 1090 1106 1136 1241 1295 1410 1417 1428 1463 1547 1559 1730\n",
            " 1784 1930 1942 2113 2120 2127 2169 2241 2252 2265 2361 2443 2457 2489\n",
            " 2641 2681 2760 2895 2938 3257 3450 3606 3700 3991 3998 4009]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "1 samples left to be tested\n",
            "1020-receipt.jpg\n",
            "(1, 64, 64, 1) (0,) (0,)\n",
            "\t >>time per step: 1.56s <<\n",
            "len(data_input_flat): 4096\n",
            "indexes: [  87   96  209  217  226  332  340  349  356  362  405  480  644  649\n",
            "  653  694  750  803  835  841  846  850  880  885  971 1014 1028 1071\n",
            " 1115 1153 1157 1162 1203 1281 1287 1297 1306 1331 1409 1413 1416 1460\n",
            " 1477 1537 1546 1553 1564 1587 1601 1605 1798 1806 1843 2051 2058 2099\n",
            " 2164 2179 2183 2290 2417 2442 2484 2499 2673 2757 2963 2977 2984 3155\n",
            " 3161 3167 3180 3205 3213 3260 3266 3274 3281 3293 3308 3317 3365 3372\n",
            " 3379 3382 3388 3394 3402 3414 3423 3568 3590 3603 3614 3621 3907 3910\n",
            " 3914 3919 3924]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "EVALUATION ACC (Recall/Acc): 0.333 / 0.000 (0.167) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQAQb8MUNNyq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}