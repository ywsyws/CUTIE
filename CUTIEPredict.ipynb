{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUTIEPredict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhjzsOGVKBYtuGJU9aMC9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ywsyws/CUTIE/blob/main/CUTIEPredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfbll7kVBRHA"
      },
      "source": [
        "------------------------------\n",
        "# Please see CUTIETrain notebook for project information.\n",
        "------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWhBfOuC7-_7"
      },
      "source": [
        "# 0. Preparation\n",
        "## 0.1 Environment Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8FCvV-mKM-J",
        "outputId": "cc01d750-296c-4db2-8d1a-41cdcd0357a0"
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip3 install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 92kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4so9rA1cKpoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec84752-35eb-47e5-aac1-29d13b3a14b8"
      },
      "source": [
        "# Mount Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0XapWpKszj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beade2da-db8e-4a1b-dd9f-2b6d89ec4f29"
      },
      "source": [
        "# Import libraries\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior() \n",
        "\n",
        "import json, re, random, argparse, timeit, cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from os import chdir, walk, makedirs\n",
        "from os.path import basename, split, join, exists\n",
        "from collections import defaultdict\n",
        "import unicodedata\n",
        "from pprint import pprint"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWua9ZGiKv1t"
      },
      "source": [
        "# Set root path for this project\n",
        "root_path = r'/content/gdrive/MyDrive/Colab Notebooks/CUTIE/'\n",
        "# Change working directory\n",
        "chdir(root_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVoJWoZP8dCY"
      },
      "source": [
        "## 0.2 Basic Data Preparation\n",
        "Get some basic data information in order to capture total amount on receipts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE_fx8eKfOb5"
      },
      "source": [
        "# Helper functions\n",
        "\n",
        "def vis_bbox(data_loader, file_prefix, grid_table, gt_classes, model_output_val, file_name, bboxes, shape):\n",
        "    data_input_flat = grid_table.reshape([-1])\n",
        "    labels = gt_classes.reshape([-1])\n",
        "    logits = model_output_val.reshape([-1, data_loader.num_classes])\n",
        "    bboxes = bboxes.reshape([-1])\n",
        "    \n",
        "    # Set upper boundary of image display size\n",
        "    max_len = 768*2  \n",
        "    img = cv2.imread(join(file_prefix, file_name))\n",
        "    if img is not None:    \n",
        "        shape = list(img.shape)\n",
        "        \n",
        "        bbox_pad = 1\n",
        "        gt_color = [[255, 250, 240], [152, 245, 255], [119,204,119], [100, 149, 237], \n",
        "                    [192, 255, 62], [119,119,204], [114,124,114], [240, 128, 128], [255, 105, 180]]\n",
        "        inf_color = [[255, 222, 173], [0, 255, 255], [50,219,50], [72, 61, 139], \n",
        "                     [154, 205, 50], [50,50,219], [64,76,64], [255, 0, 0], [255, 20, 147]]\n",
        "        \n",
        "        font_size = 0.5\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX\n",
        "        ft_color = [50, 50, 250]\n",
        "        \n",
        "        factor = max_len / max(shape)\n",
        "        shape[0], shape[1] = [int(s*factor) for s in shape[:2]]\n",
        "        \n",
        "        img = cv2.resize(img, (shape[1], shape[0]))        \n",
        "        overlay_box = np.zeros(shape, dtype=img.dtype)\n",
        "        overlay_line = np.zeros(shape, dtype=img.dtype)\n",
        "        for i in range(len(data_input_flat)):\n",
        "            if len(bboxes[i]) > 0:\n",
        "                x,y,w,h = [int(p*factor) for p in bboxes[i]]\n",
        "            else:\n",
        "                row = i // data_loader.rows\n",
        "                col = i % data_loader.cols\n",
        "                x = shape[1] // data_loader.cols * col\n",
        "                y = shape[0] // data_loader.rows * row\n",
        "                w = shape[1] // data_loader.cols * 2\n",
        "                h = shape[0] // data_loader.cols * 2\n",
        "                \n",
        "            if data_input_flat[i] and labels[i]:\n",
        "                gt_id = labels[i]                \n",
        "                cv2.rectangle(overlay_box, (x,y), (x+w,y+h), gt_color[gt_id], -1)\n",
        "                    \n",
        "            if max(logits[i]) > c_threshold:\n",
        "                inf_id = np.argmax(logits[i])\n",
        "                if inf_id:                \n",
        "                    cv2.rectangle(overlay_line, (x+bbox_pad,y+bbox_pad), \\\n",
        "                                  (x+bbox_pad+w,y+bbox_pad+h), inf_color[inf_id], max_len//768*2)\n",
        "        \n",
        "        # Legends\n",
        "        w = shape[1] // data_loader.cols * 4\n",
        "        h = shape[0] // data_loader.cols * 2\n",
        "        for i in range(1, len(data_loader.classes)):\n",
        "            row = i * 3\n",
        "            col = 0\n",
        "            x = shape[1] // data_loader.cols * col\n",
        "            y = shape[0] // data_loader.rows * row \n",
        "            cv2.rectangle(img, (x,y), (x+w,y+h), gt_color[i], -1)\n",
        "            cv2.putText(img, data_loader.classes[i], (x+w,y+h), font, 0.8, ft_color)  \n",
        "            \n",
        "            row = i * 3 + 1\n",
        "            col = 0\n",
        "            x = shape[1] // data_loader.cols * col\n",
        "            y = shape[0] // data_loader.rows * row \n",
        "            cv2.rectangle(img, (x+bbox_pad,y+bbox_pad), \\\n",
        "                          (x+bbox_pad+w,y+bbox_pad+h), inf_color[i], max_len//384)        \n",
        "        \n",
        "        alpha = 0.4\n",
        "        cv2.addWeighted(overlay_box, alpha, img, 1-alpha, 0, img)\n",
        "        cv2.addWeighted(overlay_line, 1-alpha, img, 1, 0, img)\n",
        "        cv2.imwrite('results/' + file_name[:-4]+'.png', img)        \n",
        "        cv2_imshow(img)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "\n",
        "def cal_accuracy(c_threshold, data_loader, grid_table, gt_classes, model_output_val, label_mapids, bbox_mapids):\n",
        "    \"\"\" Calculate accuracy and related indicators\n",
        "    \"\"\"\n",
        "    res = ''\n",
        "    num_correct = 0\n",
        "    num_correct_strict = 0\n",
        "    num_correct_soft = 0\n",
        "    num_all = grid_table.shape[0] * (model_output_val.shape[-1]-1)\n",
        "    for b in range(grid_table.shape[0]):\n",
        "        data_input_flat = grid_table[b,:,:,0].reshape([-1])\n",
        "        labels = gt_classes[b,:,:].reshape([-1])\n",
        "        logits = model_output_val[b,:,:,:].reshape(([-1, data_loader.num_classes]))\n",
        "        label_mapid = label_mapids[b]\n",
        "        bbox_mapid = bbox_mapids[b]\n",
        "        rows, cols = grid_table.shape[1:3]\n",
        "        bbox_id = np.array([row*cols+col for row in range(rows) for col in range(cols)])\n",
        "        \n",
        "        # Ignore inputs that are not word\n",
        "        indexes = np.where(data_input_flat != 0)[0]\n",
        "        print(f'len(data_input_flat): {len(data_input_flat)}')\n",
        "        print(f'indexes: {indexes}')\n",
        "        data_selected = data_input_flat[indexes]\n",
        "        labels_selected = labels[indexes]\n",
        "        logits_array_selected = logits[indexes]\n",
        "        bbox_id_selected = bbox_id[indexes]\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        for c in range(1, data_loader.num_classes):\n",
        "            labels_indexes = np.where(labels_selected == c)[0]\n",
        "            logits_indexes = np.where(logits_array_selected[:,c] > c_threshold)[0]\n",
        "            \n",
        "            labels_words = list(data_loader.index_to_word[i] for i in data_selected[labels_indexes])\n",
        "            logits_words = list(data_loader.index_to_word[i] for i in data_selected[logits_indexes])\n",
        "            \n",
        "            label_bbox_ids = label_mapid[c] # GT bbox_ids related to the type of class\n",
        "            logit_bbox_ids = [bbox_mapid[bbox] for bbox in bbox_id_selected[logits_indexes] if bbox in bbox_mapid]            \n",
        "\n",
        "            # Decide as correct when all ids match\n",
        "            if set(label_bbox_ids) == set(logit_bbox_ids):\n",
        "                num_correct_strict += 1  \n",
        "                num_correct_soft += 1\n",
        "            # Decide as correct when gt is subset of gt\n",
        "            elif set(label_bbox_ids).issubset(set(logit_bbox_ids)):\n",
        "                num_correct_soft += 1\n",
        "            # Calculate prevalence with decimal precision\n",
        "            try: \n",
        "                num_correct += np.shape(np.intersect1d(labels_indexes, logits_indexes))[0] / np.shape(labels_indexes)[0]\n",
        "            except ZeroDivisionError:\n",
        "                if np.shape(labels_indexes)[0] == 0:\n",
        "                    num_correct += 1\n",
        "                else:\n",
        "                    num_correct += 0        \n",
        "            \n",
        "            # Show results without the 'DontCare' class                    \n",
        "            if b==0:\n",
        "                res += '\\n{}(GT/Inf):\\t\"'.format(data_loader.classes[c])\n",
        "                \n",
        "                # Ground truth label\n",
        "                res += ' '.join(data_loader.index_to_word[i] for i in data_selected[labels_indexes])\n",
        "                res += '\" | \"'\n",
        "                res += ' '.join(data_loader.index_to_word[i] for i in data_selected[logits_indexes])\n",
        "                res += '\"'\n",
        "                \n",
        "                # Wrong inferences results\n",
        "                if not np.array_equal(labels_indexes, logits_indexes): \n",
        "                    res += '\\n \\t FALSES =>>'\n",
        "                    logits_flat = logits_array_selected[:,c]\n",
        "                    fault_logits_indexes = np.setdiff1d(logits_indexes, labels_indexes)\n",
        "                    for i in range(len(data_selected)):\n",
        "                        # Only show fault_logits_indexes\n",
        "                        if i not in fault_logits_indexes:\n",
        "                            continue\n",
        "                        w = data_loader.index_to_word[data_selected[i]]\n",
        "                        l = data_loader.classes[labels_selected[i]]\n",
        "                        res += ' \"%s\"/%s, '%(w, l)\n",
        "                        \n",
        "    prevalence = num_correct / num_all\n",
        "    accuracy_strict = num_correct_strict / num_all\n",
        "    accuracy_soft = num_correct_soft / num_all\n",
        "    return prevalence, accuracy_strict, accuracy_soft, res.encode(\"utf-8\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMiXK63nMUF3"
      },
      "source": [
        "# DEBUG = True # True = show grid as image \n",
        "\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass \n",
        "    return False\n",
        "\n",
        "class DataLoader():\n",
        "    \"\"\"\n",
        "    Generate grid tables\n",
        "    \"\"\"\n",
        "    def __init__(self, params, update_dict=True, load_dictionary=False, data_split=0.75):\n",
        "        # Assign parameters\n",
        "        self.random = False\n",
        "        self.encoding_factor = 1 # ensures the size (rows/cols) of grid table compat with the network\n",
        "        self.classes = ['O', 'TTL']\n",
        "        \n",
        "        self.doc_path = params.doc_path\n",
        "        self.use_cutie2 = params.use_cutie2\n",
        "        \n",
        "        self.segment_grid = params.segment_grid if hasattr(params, 'segment_grid') else False # segment grid into two parts if grid is larger than cols_target\n",
        "        self.rows_target = params.rows_target if hasattr(params, 'rows_target') else 64 \n",
        "        self.cols_target = params.cols_target if hasattr(params, 'cols_target') else 64 \n",
        "        \n",
        "        # Set up parameters to be tuned\n",
        "        self.load_dictionary = load_dictionary # load dictionary from file rather than start from empty \n",
        "        self.dict_path = params.load_dict_from_path if load_dictionary else params.dict_path\n",
        "        if self.load_dictionary:\n",
        "            self.dictionary = np.load(self.dict_path + 'dictionary.npy', allow_pickle=True).item()\n",
        "            self.word_to_index = np.load(self.dict_path + 'word_to_index.npy', allow_pickle=True).item()\n",
        "            self.index_to_word = np.load(self.dict_path + 'index_to_word.npy', allow_pickle=True).item()\n",
        "        else:\n",
        "            self.dictionary = {'[PAD]':0, '[UNK]':0} # word/counts. to be updated in self.load_data() and self.update_docs_dictionary()\n",
        "            self.word_to_index = {}\n",
        "            self.index_to_word = {}\n",
        "\n",
        "        self.data_split = data_split # split data to training/validation, 0 for all for validation\n",
        "        \n",
        "        self.num_classes = len(self.classes)  \n",
        "        \n",
        "        # Build a special cared dictionary\n",
        "        self.special_dict = {'*', '='} # map texts to specific tokens        \n",
        "        \n",
        "        # Load words and their location/class as training/validation docs and labels \n",
        "        self.training_doc_files = self.get_filenames(self.doc_path)\n",
        "        self.training_docs, self.training_labels = self.load_data(self.training_doc_files, update_dict=update_dict) # TBD: optimize the update dict flag\n",
        "        \n",
        "        # Polish and load dictionary/word_to_index/index_to_word as file\n",
        "        self.num_words = len(self.dictionary)\n",
        "        \n",
        "        # Split training / validation docs to get validation docs related variables\n",
        "        num_training = int(len(self.training_docs)*self.data_split)\n",
        "        data_to_be_fetched = [i for i in range(len(self.training_docs))]\n",
        "        selected_training_index = data_to_be_fetched[:num_training] \n",
        "        if self.random:\n",
        "            selected_training_index = random.sample(data_to_be_fetched, num_training)\n",
        "        selected_validation_index = list(set(data_to_be_fetched).difference(set(selected_training_index)))\n",
        "        self.validation_docs = [self.training_docs[x] for x in selected_validation_index]\n",
        "        self.validation_labels = self.training_labels\n",
        "        self.validation_data_tobe_fetched = [i for i in range(len(self.validation_docs))]\n",
        "\n",
        "\n",
        "    def fetch_validation_data(self):\n",
        "        \"\"\" Get validation data\n",
        "        \"\"\"\n",
        "        batch_size = 1\n",
        "        \n",
        "        while True:\n",
        "            if len(self.validation_data_tobe_fetched) == 0:\n",
        "                self.validation_data_tobe_fetched = [i for i in range(len(self.validation_docs))]            \n",
        "            selected_index = random.sample(self.validation_data_tobe_fetched, 1)\n",
        "            self.validation_data_tobe_fetched = list(set(self.validation_data_tobe_fetched).difference(set(selected_index)))\n",
        "    \n",
        "            validation_docs = [self.validation_docs[x] for x in selected_index]\n",
        "            \n",
        "            real_rows, real_cols, _, _ = self.cal_rows_cols(validation_docs)\n",
        "            rows = max(self.rows_target, real_rows)\n",
        "            cols = max(self.rows_target, real_cols)\n",
        "            \n",
        "            grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, updated_cols, ps_indices_x, ps_indices_y = \\\n",
        "                self.positional_mapping(validation_docs, self.validation_labels, rows, cols)   \n",
        "            if updated_cols > cols:\n",
        "                print('Validation grid EXPAND size: ({},{}) from ({},{})'\\\n",
        "                      .format(rows, updated_cols, rows, cols))\n",
        "                grid_table, gt_classes, bboxes, label_mapids, bbox_mapids, file_names, _, ps_indices_x, ps_indices_y = \\\n",
        "                    self.positional_mapping(validation_docs, self.validation_labels, rows, updated_cols, update_col=False)     \n",
        "            \n",
        "            ## Load image and generate corresponding @ps_1d_indices\n",
        "            images, ps_1d_indices = [], []\n",
        "            if self.use_cutie2:\n",
        "                images, ps_1d_indices = self.positional_sampling(self.doc_path, file_names, ps_indices_x, ps_indices_y, updated_cols)  \n",
        "                if len(images) == batch_size:\n",
        "                    break        \n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        batch = {'grid_table': np.array(grid_table), 'gt_classes': np.array(gt_classes), \n",
        "                 'data_image': np.array(images), 'ps_1d_indices': np.array(ps_1d_indices), # @images and @ps_1d_indices are only used for CUTIEv2\n",
        "                 'bboxes': bboxes, 'label_mapids': label_mapids, 'bbox_mapids': bbox_mapids,\n",
        "                 'file_name': file_names, 'shape': [rows,cols]}\n",
        "        return batch\n",
        "\n",
        "        \n",
        "    def data_shape_statistic(self):        \n",
        "        def shape_statistic(docs):\n",
        "            res_all = defaultdict(int)\n",
        "            res_row = defaultdict(int)\n",
        "            res_col = defaultdict(int)\n",
        "            for doc in docs:\n",
        "                rows, cols, _, _ = self.cal_rows_cols([doc])\n",
        "                res_all[rows] += 1\n",
        "                res_all[cols] += 1\n",
        "                res_row[rows] += 1\n",
        "                res_col[cols] += 1\n",
        "            res_all = sorted(res_all.items(), key=lambda x:x[0], reverse=True)\n",
        "            res_row = sorted(res_row.items(), key=lambda x:x[0], reverse=True)\n",
        "            res_col = sorted(res_col.items(), key=lambda x:x[0], reverse=True)\n",
        "            return res_all, res_row, res_col\n",
        "\n",
        "         # Training / Validation / Test shape static\n",
        "        tss, tss_r, tss_c = shape_statistic(self.training_docs)\n",
        "        vss, vss_r, vss_c = shape_statistic(self.validation_docs)\n",
        "        tess, tess_r, tess_c = shape_statistic(self.test_docs)\n",
        "        print(\"Training statistic: \", tss)\n",
        "        print(\"\\t num: \", len(self.training_docs))\n",
        "        print(\"\\t rows statistic: \", tss_r)\n",
        "        print(\"\\t cols statistic: \", tss_c)\n",
        "        print(\"\\nValidation statistic: \", vss)\n",
        "        print(\"\\t num: \", len(self.validation_docs))\n",
        "        print(\"\\t rows statistic: \", vss_r)\n",
        "        print(\"\\t cols statistic: \", vss_c)\n",
        "        print(\"\\nTest statistic: \", tess)\n",
        "        print(\"\\t num: \", len(self.test_docs))\n",
        "        print(\"\\t rows statistic: \", tess_r)\n",
        "        print(\"\\t cols statistic: \", tess_c)\n",
        "        \n",
        "        \n",
        "        def data_laundry(docs):\n",
        "            \"\"\" Remove data samples not matching the training principle\n",
        "            \"\"\"\n",
        "            idx = 0\n",
        "            while idx < len(docs):\n",
        "                rows, cols, _, _ = self.cal_rows_cols([docs[idx]])\n",
        "                if rows > self.rows_ulimit or cols > self.cols_ulimit:\n",
        "                    del docs[idx]\n",
        "                else:\n",
        "                    idx += 1\n",
        "        \n",
        "        if self.data_laundry:\n",
        "            print(\"\\nRemoving grids with shape larger than ({},{}).\".format(self.rows_ulimit, self.cols_ulimit))\n",
        "            data_laundry(self.training_docs)\n",
        "            data_laundry(self.validation_docs)\n",
        "            data_laundry(self.training_docs)\n",
        "        \n",
        "            # Training / Validation / Test shape static\n",
        "            tss, tss_r, tss_c = shape_statistic(self.training_docs)\n",
        "            vss, vss_r, vss_c = shape_statistic(self.validation_docs)\n",
        "            tess, tess_r, tess_c = shape_statistic(self.test_docs)\n",
        "            print(\"Training statistic after laundary: \", tss)\n",
        "            print(\"\\t num: \", len(self.training_docs))\n",
        "            print(\"\\t rows statistic: \", tss_r)\n",
        "            print(\"\\t cols statistic: \", tss_c)\n",
        "            print(\"Validation statistic after laundary: \", vss)\n",
        "            print(\"\\t num: \", len(self.validation_docs))\n",
        "            print(\"\\t rows statistic: \", vss_r)\n",
        "            print(\"\\t cols statistic: \", vss_c)\n",
        "            print(\"Test statistic after laundary: \", tess)\n",
        "            print(\"\\t num: \", len(self.test_docs))\n",
        "            print(\"\\t rows statistic: \", tess_r)\n",
        "            print(\"\\t cols statistic: \", tess_c)\n",
        "    \n",
        "    def positional_mapping(self, docs, labels, rows, cols):\n",
        "        \"\"\"\n",
        "        docs in format:\n",
        "        [[file_name, text, word_id, [x_left, y_top, x_right, y_bottom], [left, top, right, bottom], max_row_words, max_col_words] ]\n",
        "        return grid_tables, gird_labels, dict bboxes {file_name:[]}, file_names\n",
        "        \"\"\"\n",
        "        grid_tables = []\n",
        "        gird_labels = []\n",
        "        ps_indices_x = [] # positional sampling indices\n",
        "        ps_indices_y = [] # positional sampling indices\n",
        "        bboxes = {}\n",
        "        label_mapids = []\n",
        "        bbox_mapids = [] # [{}, ] bbox identifier, each id with one or multiple bbox/bboxes\n",
        "        file_names = []\n",
        "        for doc in docs:\n",
        "            items = []\n",
        "            cols_e = 2 * cols # use @cols_e larger than required @cols as buffer\n",
        "            grid_table = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            grid_label = np.zeros([rows, cols_e], dtype=np.int8)\n",
        "            ps_x = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            ps_y = np.zeros([rows, cols_e], dtype=np.int32)\n",
        "            bbox = [[] for c in range(cols_e) for r in range(rows)]\n",
        "            bbox_id, bbox_mapid = 0, {} # one word in one or many positions in a bbox is mapped in bbox_mapid\n",
        "            label_mapid = [[] for _ in range(self.num_classes)] # each class is connected to several bboxes (words)\n",
        "            drawing_board = np.zeros([rows, cols_e], dtype=str)\n",
        "            for item in doc:\n",
        "                file_name = item[0]\n",
        "                text = item[1]\n",
        "                word_id = item[2]\n",
        "                x_left, y_top, x_right, y_bottom = item[3][:]\n",
        "                left, top, right, bottom = item[4][:]\n",
        "                \n",
        "                dict_id = self.word_to_index[text]                \n",
        "                entity_id, class_id = self.dress_class(file_name, word_id, labels)\n",
        "                \n",
        "                bbox_id += 1\n",
        "                label_mapid[class_id].append(bbox_id)    \n",
        "                \n",
        "                box_y = y_top + (y_bottom-y_top)/2\n",
        "                box_x = x_left \n",
        "                v_c = (y_top - top + (y_bottom-y_top)/2) / (bottom-top)\n",
        "                h_c = (x_left - left + (x_right-x_left)/2) / (right-left) # h_c is used for sorting items\n",
        "                row = int(rows * v_c) \n",
        "                col = int(cols * h_c) \n",
        "                items.append([row, col, [box_y, box_x], [v_c, h_c], file_name, dict_id, class_id, entity_id, bbox_id, [x_left, y_top, x_right-x_left, y_bottom-y_top]])                       \n",
        "            \n",
        "            # Sort according to row > h_c > bbox_id\n",
        "            items.sort(key=lambda x: (x[0], x[3], x[5])) \n",
        "            for item in items:\n",
        "                row, col, [box_y, box_x], [v_c, h_c], file_name, dict_id, class_id, entity_id, bbox_id, box = item\n",
        "                entity_class_id = entity_id*self.num_classes + class_id\n",
        "                \n",
        "                while col < cols and grid_table[row, col] != 0:\n",
        "                    col += 1            \n",
        "                \n",
        "                ptr = 0\n",
        "                # Shift to find slot to drop the current item\n",
        "                if col == cols: \n",
        "                    col -= 1\n",
        "                    while ptr<cols and grid_table[row, ptr] != 0:\n",
        "                        ptr += 1\n",
        "                    if ptr == cols:\n",
        "                        grid_table[row, :-1] = grid_table[row, 1:]\n",
        "                    else:\n",
        "                        grid_table[row, ptr:-1] = grid_table[row, ptr+1:]\n",
        "                \n",
        "                grid_table[row, col] = dict_id\n",
        "                grid_label[row, col] = entity_class_id\n",
        "                ps_x[row, col] = box_x\n",
        "                ps_y[row, col] = box_y\n",
        "                bbox_mapid[row*cols+col] = bbox_id     \n",
        "                bbox[row*cols+col] = box\n",
        "                \n",
        "            cols = self.fit_shape(cols)\n",
        "            grid_table = grid_table[..., :cols]\n",
        "            grid_label = grid_label[..., :cols]\n",
        "            ps_x = np.array(ps_x[..., :cols])\n",
        "            ps_y = np.array(ps_y[..., :cols])\n",
        "            \n",
        "            # if DEBUG:\n",
        "            #     self.grid_visualization(file_name, grid_table, grid_label)\n",
        "            \n",
        "            grid_tables.append(np.expand_dims(grid_table, -1)) \n",
        "            gird_labels.append(grid_label) \n",
        "            ps_indices_x.append(ps_x)\n",
        "            ps_indices_y.append(ps_y)\n",
        "            bboxes[file_name] = bbox\n",
        "            label_mapids.append(label_mapid)\n",
        "            bbox_mapids.append(bbox_mapid)\n",
        "            file_names.append(file_name)\n",
        "            \n",
        "        return grid_tables, gird_labels, bboxes, label_mapids, bbox_mapids, file_names, cols, ps_indices_x, ps_indices_y\n",
        "    \n",
        "    def positional_sampling(self, path, file_names, ps_indices_x, ps_indices_y, updated_cols):\n",
        "        images, ps_1d_indices = [], []\n",
        "        \n",
        "        # Load image and generate corresponding @ps_1d_indices\n",
        "        max_h, max_w = 0, updated_cols\n",
        "        for i in range(len(file_names)):\n",
        "            file_name = file_names[i]\n",
        "            file_path = join(path, file_name) # TBD: ensure image is upright\n",
        "            ps_1d_x = np.array(ps_indices_x[i], dtype=np.float32).reshape([-1])\n",
        "            ps_1d_y = np.array(ps_indices_y[i], dtype=np.float32).reshape([-1])\n",
        "            \n",
        "            image = cv2.imread(file_path)\n",
        "            if image is not None:\n",
        "                h, w, _ = image.shape # [h,w,c]\n",
        "                factor = max_w / w\n",
        "                \n",
        "                h = int(h*factor)\n",
        "                ps_1d_x *= factor # TBD: implement more accurate mapping method rather than nearest neighbor, since the .4 or .6 leads to two different sampling results\n",
        "                ps_1d_y *= factor                \n",
        "                \n",
        "                ps_1d = np.int32(np.floor(ps_1d_x) + np.floor(ps_1d_y) * max_w)\n",
        "                max_items = max_w * h - 1\n",
        "                for i in range(len(ps_1d)):\n",
        "                    if ps_1d[i] > max_items - 1:\n",
        "                        ps_1d[i] = max_items - 1\n",
        "                    \n",
        "                \n",
        "                image = cv2.resize(image, (max_w, h))\n",
        "                image = (image-127.5) / 255\n",
        "            else:\n",
        "                print('{} ignored due to image file not found.'.format(file_path))\n",
        "                image, ps_1d = None, None\n",
        "                break\n",
        "                \n",
        "            if image is not None and ps_1d is not None: # ignore data with no images                 \n",
        "                ps_1d_indices.append(ps_1d)\n",
        "                images.append(image)\n",
        "                h,w,c = image.shape\n",
        "                if h > max_h:\n",
        "                    max_h = h\n",
        "            else:\n",
        "                pass\n",
        "                \n",
        "        ## Pad image to the same shape\n",
        "        for i,image in enumerate(images): \n",
        "            pad_img = np.zeros([max_h, max_w, 3], dtype=image.dtype)\n",
        "            pad_img[:image.shape[0], :, :] = image\n",
        "            images[i] = pad_img\n",
        "        \n",
        "        return images, ps_1d_indices\n",
        "    \n",
        "    def load_data(self, data_files, update_dict=False):\n",
        "        \"\"\"\n",
        "        Return:\n",
        "        doc_dressed with location and class returned in format: \n",
        "        [[file_name, text, word_id, [x_left, y_top, x_right, y_bottom], [left, top, right, bottom], max_row_words, max_col_words] ]\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        \"\"\"\n",
        "        label_dressed = {}\n",
        "        doc_dressed = []\n",
        "        if not data_files:\n",
        "            print(\"no data file found.\")        \n",
        "        for file in data_files:\n",
        "            with open(file, encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                file_id = data['global_attributes']['file_id']\n",
        "                \n",
        "                label = self.collect_label(file_id, data['fileds'])\n",
        "                # ignore corrupted data\n",
        "                if not label:\n",
        "                    continue                \n",
        "                label_dressed.update(label) \n",
        "                \n",
        "                data = self.collect_data(file_id, data['text_boxes'], update_dict)\n",
        "                for i in data:\n",
        "                    doc_dressed.append(i)\n",
        "                    \n",
        "        return doc_dressed, label_dressed       \n",
        "    \n",
        "    \n",
        "    def cal_rows_cols(self, docs, ropout=False):                  \n",
        "        max_row = self.encoding_factor\n",
        "        max_col = self.encoding_factor\n",
        "        for doc in docs:\n",
        "            for line in doc: \n",
        "                _, _, _, _, _, max_row_words, max_col_words = line\n",
        "                if max_row_words > max_row:\n",
        "                    max_row = max_row_words\n",
        "                if max_col_words > max_col:\n",
        "                    max_col = max_col_words\n",
        "        \n",
        "        pre_rows = self.fit_shape(max_row) \n",
        "        pre_cols = self.fit_shape(max_col) \n",
        "        \n",
        "        rows = pre_rows\n",
        "        cols = pre_cols\n",
        "        return rows, cols, pre_rows, pre_cols \n",
        "    \n",
        "    def fit_shape(self, shape): \n",
        "        \"\"\" Modify shape size to fit the encoding factor\n",
        "        \"\"\"\n",
        "        while shape % self.encoding_factor:\n",
        "            shape += 1\n",
        "        return shape\n",
        "    \n",
        "    def expand_shape(self, shape): \n",
        "        \"\"\" Expand shape size with step of 2\n",
        "        \"\"\"\n",
        "        return self.fit_shape(shape+1)\n",
        "        \n",
        "    def collect_data(self, file_name, content, update_dict):\n",
        "        \"\"\"\n",
        "        Dress and preserve only interested data.\n",
        "        \"\"\"          \n",
        "        content_dressed = []\n",
        "        left, top, right, bottom, buffer = 9999, 9999, 0, 0, 2\n",
        "        for line in content:\n",
        "            # Handle data corrupt\n",
        "            bbox = line['bbox'] \n",
        "            if len(bbox) == 0:\n",
        "                continue\n",
        "            # Ignore potential overlap causing characters\n",
        "            if line['text'] in self.special_dict:\n",
        "                continue\n",
        "            \n",
        "            x_left, y_top, x_right, y_bottom = self.dress_bbox(bbox)        \n",
        "            # Calculate relative x/y/w/h\n",
        "            if x_left < left: \n",
        "              left = x_left - buffer\n",
        "            if y_top < top: \n",
        "              top = y_top - buffer\n",
        "            if x_right > right: \n",
        "              right = x_right + buffer\n",
        "            if y_bottom > bottom: \n",
        "              bottom = y_bottom + buffer\n",
        "            \n",
        "            word_id = line['word_id']\n",
        "            dressed_texts = self.dress_text(line['text'], update_dict)\n",
        "            \n",
        "            num_block = len(dressed_texts)\n",
        "            # Handling tokenized text, separate bbox\n",
        "            for i, dressed_text in enumerate(dressed_texts): \n",
        "                new_left = int(x_left + (x_right-x_left) / num_block * (i))\n",
        "                new_right = int(x_left + (x_right-x_left) / num_block * (i+1))\n",
        "                content_dressed.append([file_name, dressed_text, word_id, [new_left, y_top, new_right, y_bottom]])\n",
        "            \n",
        "        # Initial calculation of maximum number of words in rows/cols in terms of image size\n",
        "        num_words_row = [0 for _ in range(bottom)] # number of words in each row\n",
        "        num_words_col = [0 for _ in range(right)] # number of words in each column\n",
        "        for line in content_dressed:\n",
        "            _, _, _, [x_left, y_top, x_right, y_bottom] = line\n",
        "            for y in range(y_top, y_bottom):\n",
        "                num_words_row[y] += 1\n",
        "            for x in range(x_left, x_right):\n",
        "                num_words_col[x] += 1\n",
        "        max_row_words = self.fit_shape(max(num_words_row))\n",
        "        max_col_words = 0\n",
        "        \n",
        "        # Further expansion of maximum number of words in rows/cols in terms of grid shape\n",
        "        max_rows = max(self.encoding_factor, max_row_words)\n",
        "        max_cols = max(self.encoding_factor, max_col_words)\n",
        "        DONE = False\n",
        "        while not DONE:\n",
        "            DONE = True\n",
        "            grid_table = np.zeros([max_rows, max_cols], dtype=np.int32)\n",
        "            for line in content_dressed:\n",
        "                _, _, _, [x_left, y_top, x_right, y_bottom] = line\n",
        "                row = int(max_rows * (y_top - top + (y_bottom-y_top)/2) / (bottom-top))\n",
        "                col = int(max_cols * (x_left - left + (x_right-x_left)/2) / (right-left))\n",
        "                \n",
        "                # Shift to find slot to drop the current item\n",
        "                while col < max_cols and grid_table[row, col] != 0: \n",
        "                    col += 1\n",
        "                if col == max_cols: \n",
        "                    col -= 1\n",
        "                    ptr = 0\n",
        "                    while ptr<max_cols and grid_table[row, ptr] != 0:\n",
        "                        ptr += 1\n",
        "                    # If overlap cannot be solved in current row, then expand the grid\n",
        "                    if ptr == max_cols:\n",
        "                        max_cols = self.expand_shape(max_cols)\n",
        "                        DONE = False\n",
        "                        break\n",
        "                    \n",
        "                    grid_table[row, ptr:-1] = grid_table[row, ptr+1:]\n",
        "                \n",
        "                if DONE:\n",
        "                    if row > max_rows or col>max_cols:\n",
        "                        print('wrong')\n",
        "                    grid_table[row, col] = 1\n",
        "        \n",
        "        max_rows = self.fit_shape(max_rows)\n",
        "        max_cols = self.fit_shape(max_cols)\n",
        "        \n",
        "        # Segment grid into two parts if number of cols is larger than self.cols_target\n",
        "        data = []\n",
        "        if self.segment_grid and max_cols > self.cols_segment:\n",
        "            content_dressed_left = []\n",
        "            content_dressed_right = []\n",
        "            cnt = defaultdict(int) # counter for number of words in a specific row\n",
        "            cnt_l, cnt_r = defaultdict(int), defaultdict(int) # update max_cols if larger than self.cols_segment\n",
        "            left_boundary = max_cols - self.cols_segment\n",
        "            right_boundary = self.cols_segment\n",
        "            for i, line in enumerate(content_dressed):\n",
        "                file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom] = line\n",
        "                \n",
        "                row = int(max_rows * (y_top + (y_bottom-y_top)/2) / bottom)\n",
        "                cnt[row] += 1                \n",
        "                if cnt[row] <= left_boundary:\n",
        "                    cnt_l[row] += 1\n",
        "                    content_dressed_left.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, self.cols_segment])\n",
        "                elif left_boundary < cnt[row] <= right_boundary:\n",
        "                    cnt_l[row] += 1\n",
        "                    cnt_r[row] += 1\n",
        "                    content_dressed_left.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, self.cols_segment])\n",
        "                    content_dressed_right.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max(max(cnt_r.values()), self.cols_segment)])\n",
        "                else:\n",
        "                    cnt_r[row] += 1\n",
        "                    content_dressed_right.append([file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max(max(cnt_r.values()), self.cols_segment)])\n",
        "            if max(cnt_l.values()) < 2*self.cols_segment:\n",
        "                data.append(content_dressed_left)\n",
        "            # Avoid OOM, which tends to happen in the right side\n",
        "            if max(cnt_r.values()) < 2*self.cols_segment: \n",
        "                data.append(content_dressed_right)\n",
        "        else:\n",
        "            # Append height/width/numofwords to the list\n",
        "            for i, line in enumerate(content_dressed):\n",
        "                file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom] = line\n",
        "                content_dressed[i] = [file_name, dressed_text, word_id, [x_left, y_top, x_right, y_bottom], \\\n",
        "                                      [left, top, right, bottom], max_rows, max_cols ]\n",
        "            data.append(content_dressed)\n",
        "        return data\n",
        "    \n",
        "    def collect_label(self, file_id, content):\n",
        "        \"\"\"\n",
        "        Dress and preserve only interested data.\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        \"\"\"\n",
        "        label_dressed = dict()\n",
        "        label_dressed[file_id] = {cls:[] for cls in self.classes[1:]}\n",
        "        for line in content:\n",
        "            cls = line['field_name']\n",
        "            if cls in self.classes:\n",
        "                label_dressed[file_id][cls].append( {'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''} )\n",
        "                label_dressed[file_id][cls][-1]['key_id'] = line.get('key_id', [])\n",
        "                label_dressed[file_id][cls][-1]['value_id'] = line['value_id'] # value_id\n",
        "                label_dressed[file_id][cls][-1]['key_text'] = line.get('key_text', []) \n",
        "                label_dressed[file_id][cls][-1]['value_text'] = line['value_text'] # value_text\n",
        "                \n",
        "        # Handle corrupted data\n",
        "        for cls in label_dressed[file_id]: \n",
        "            for idx, label in enumerate(label_dressed[file_id][cls]):\n",
        "                if len(label) == 0: # no relevant class in sample @file_id\n",
        "                    continue\n",
        "                if (len(label['key_text'])>0 and len(label['key_id'])==0) or \\\n",
        "                   (len(label['value_text'])>0 and len(label['value_id'])==0):\n",
        "                    return None\n",
        "            \n",
        "        return label_dressed\n",
        "\n",
        "    def dress_class(self, file_name, word_id, labels):\n",
        "        \"\"\"\n",
        "        label_dressed in format:\n",
        "        {file_id: {class: [{'key_id':[], 'value_id':[], 'key_text':'', 'value_text':''}, ] } }\n",
        "        \"\"\"\n",
        "        if file_name in labels:\n",
        "            for cls, cls_labels in labels[file_name].items():\n",
        "                for idx, cls_label in enumerate(cls_labels):\n",
        "                    for key, values in cls_label.items():\n",
        "                        if (key=='key_id' or key=='value_id') and word_id in values:\n",
        "                            if key == 'key_id':\n",
        "                                return 0, 0\n",
        "                            elif key == 'value_id':\n",
        "                                return idx, self.classes.index(cls) \n",
        "            return 0, 0 # 0 is of class type 'DontCare'\n",
        "        print(\"No matched labels found for {}\".format(file_name))\n",
        "    \n",
        "    def dress_text(self, text, update_dict):\n",
        "        \"\"\"\n",
        "        Three cases covered: \n",
        "        alphabetic string, numeric string, special character\n",
        "        \"\"\"\n",
        "        string = text.lower()\n",
        "        for i, c in enumerate(string):\n",
        "            if is_number(c):\n",
        "                string = string[:i] + '0' + string[i+1:]\n",
        "                \n",
        "        strings = [string]\n",
        "            \n",
        "        for idx, string in enumerate(strings):            \n",
        "            if string.isalpha():\n",
        "                if string in self.special_dict:\n",
        "                    string = self.special_dict[string]\n",
        "            elif is_number(string):\n",
        "                pass\n",
        "            elif len(string)==1: # special character\n",
        "                pass\n",
        "            else:\n",
        "                pass            \n",
        "            \n",
        "            if string not in self.dictionary.keys():\n",
        "                if update_dict:\n",
        "                    self.dictionary[string] = 0\n",
        "                else:\n",
        "                    string = '[UNK]' # take special care to unmet words\n",
        "            self.dictionary[string] += 1\n",
        "            \n",
        "            strings[idx] = string\n",
        "        return strings\n",
        "            \n",
        "    def dress_bbox(self, bbox):\n",
        "        positions = np.array(bbox).reshape([-1])\n",
        "        x_left = max(0, min(positions[0::2]))\n",
        "        x_right = max(positions[0::2])\n",
        "        y_top = max(0, min(positions[1::2]))\n",
        "        y_bottom = max(positions[1::2])\n",
        "        w = x_right - x_left\n",
        "        h = y_bottom - y_top\n",
        "        return int(x_left), int(y_top), int(x_right), int(y_bottom)       \n",
        "    \n",
        "    def get_filenames(self, data_path):\n",
        "        files = []\n",
        "        for dirpath,dirnames,filenames in walk(data_path):\n",
        "            for filename in filenames:\n",
        "                file = join(dirpath,filename)\n",
        "                if file.endswith('csv') or file.endswith('json'):\n",
        "                    files.append(file)\n",
        "        return files       \n",
        "            \n",
        "    # def grid_visualization(self, file_name, grid, label):\n",
        "    #     height, width = np.shape(grid)\n",
        "    #     grid_box_h, grid_box_w = 20, 40\n",
        "    #     palette = np.zeros([height*grid_box_h, width*grid_box_w, 3], np.uint8)\n",
        "    #     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    #     gt_color = [[255, 250, 240], [152, 245, 255], [127, 255, 212], [100, 149, 237], \n",
        "    #                 [192, 255, 62], [175, 238, 238], [255, 130, 171], [240, 128, 128], [255, 105, 180]]\n",
        "    #     cv2.putText(palette, file_name+\"({},{})\".format(height,width), (grid_box_h,grid_box_w), font, 0.6, [255,0,0])  \n",
        "    #     for h in range(height):\n",
        "    #         cv2.line(palette, (0,h*grid_box_h), (width*grid_box_w, h*grid_box_h), (100,100,100))\n",
        "    #         for w in range(width):\n",
        "    #             if grid[h,w]:\n",
        "    #                 org = (int((w+1)*grid_box_w*0.7),int((h+1)*grid_box_h*0.9))\n",
        "    #                 color = gt_color[label[h,w]]\n",
        "    #                 cv2.putText(palette, self.index_to_word[grid[h,w]], org, font, 0.4, color)        \n",
        "        \n",
        "    #     img = cv2.imread(self.doc_path+'/'+file_name)\n",
        "    #     if img is not None:\n",
        "    #         shape = list(img.shape)\n",
        "    #         max_len = 768\n",
        "    #         factor = max_len / max(shape)\n",
        "    #         shape[0], shape[1] = [int(s*factor) for s in shape[:2]]\n",
        "    #         img = cv2.resize(img, (shape[1], shape[0]))  \n",
        "    #         cv2_imshow(img)\n",
        "    #     cv2_imshow(palette)\n",
        "    #     cv2.waitKey(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_vW3QhxLvMS"
      },
      "source": [
        "# 1. Model\n",
        "## 1.1 Set up Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04fAhXgLuwf"
      },
      "source": [
        "# Set up layers for the model framework\n",
        "\n",
        "def layer(op):\n",
        "    def layer_decorated(self, *args, **kwargs):\n",
        "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))        \n",
        "        if len(self.layer_inputs) == 0:\n",
        "            raise RuntimeError('No input variables found for layers %s' % name)\n",
        "        elif len(self.layer_inputs) == 1:\n",
        "            layer_input = self.layer_inputs[0]\n",
        "        else:\n",
        "            layer_input = list(self.layer_inputs)            \n",
        "            \n",
        "        layer_output = op(self, layer_input, *args, **kwargs)\n",
        "        \n",
        "        self.layers[name] = layer_output\n",
        "        self.feed(layer_output)\n",
        "        \n",
        "        return self\n",
        "    return layer_decorated\n",
        "    \n",
        "    \n",
        "class Model(object):\n",
        "    def __init__(self, trainable=True):\n",
        "        self.layers = dict()      \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "    \n",
        "    \n",
        "    def build_loss(self):\n",
        "        raise NotImplementedError('Must be subclassed.')\n",
        "    \n",
        "    \n",
        "    def setup(self):        \n",
        "        raise NotImplementedError('Must be subclassed.')\n",
        "     \n",
        "    \n",
        "    @layer\n",
        "    def embed(self, layer_input, vocabulary_size, embedding_size, name, dropout=1, trainable=True):\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_embedding = tf.random_uniform_initializer(-1.0, 1.0)\n",
        "            embeddings = self.make_var('weights', [vocabulary_size, embedding_size], init_embedding, None, trainable)\n",
        "            shape = tf.shape(layer_input)\n",
        "            \n",
        "            reshaped_input = tf.reshape(layer_input, [-1])\n",
        "            e = tf.nn.embedding_lookup(embeddings, reshaped_input)\n",
        "            e = tf.nn.dropout(e, dropout)\n",
        "            reshaped_e = tf.reshape(e, [shape[0], shape[1], shape[2], embedding_size])\n",
        "            return reshaped_e\n",
        "        \n",
        "        \n",
        "    @layer\n",
        "    def conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,s_h,s_w,1], 'SAME')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu') #if activation == 'relu':\n",
        "        if activation == 'sigmoid':\n",
        "            activate = lambda z: tf.nn.sigmoid(z, 'sigmoid')\n",
        "            \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "     \n",
        "     \n",
        "    @layer\n",
        "    def dilate_conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, rate, name, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.atrous_conv2d(input, filter, rate, 'SAME', 'DILATE')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu') #if activation == 'relu':\n",
        "        if activation == 'sigmoid':\n",
        "            activate = lambda z: tf.nn.sigmoid(z, 'sigmoid')\n",
        "            \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def up_conv(self, layer_input, k_h, k_w, c_o, s_h, s_w, name, factor=2, activation='relu', trainable=True):\n",
        "        convolve = lambda input, filter: tf.nn.conv2d(input, filter, [1,s_h,s_w,1], 'SAME')\n",
        "        \n",
        "        activate = lambda z: tf.nn.relu(z, 'relu')        \n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            shape = tf.shape(layer_input)\n",
        "            h = shape[1]\n",
        "            w = shape[2]\n",
        "            layer_input = tf.image.resize_nearest_neighbor(layer_input, [factor*h, factor*w])\n",
        "            init_weights = tf.compat.v1.truncated_normal_initializer(0.0, 0.01)\n",
        "            init_biases = tf.constant_initializer(0.0)\n",
        "            regularizer = self.l2_regularizer(self.weight_decay)\n",
        "            c_i = layer_input.get_shape()[-1]\n",
        "            \n",
        "            a = self.convolution(convolve, activate, layer_input, k_h, k_w, c_i, c_o, \n",
        "                                 init_weights, init_biases, regularizer, trainable)\n",
        "            return a  \n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def concat(self, layer_input, axis, name):\n",
        "        return tf.concat(layer_input, axis)\n",
        "        \n",
        "    \n",
        "    @layer\n",
        "    def max_pool(self, layer_input, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
        "        return tf.nn.max_pool(layer_input, [1,k_h,k_w,1], [1,s_h,s_w,1], name=name, padding=padding)\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def global_pool(self, layer_input, name):\n",
        "        shape = tf.shape(layer_input)\n",
        "        h = shape[1]\n",
        "        w = shape[2]\n",
        "        output = tf.reduce_mean(layer_input, [1,2], keepdims=True, name=name)\n",
        "        return tf.image.resize_nearest_neighbor(output, [h, w])\n",
        "    \n",
        "    \n",
        "    @layer\n",
        "    def softmax(self, layer_input, name):\n",
        "        return tf.nn.softmax(layer_input, name=name)      \n",
        "    \n",
        "    \n",
        "    def convolution(self, convolve, activate, input, k_h, k_w, c_i, c_o, init_weights, init_biases, \n",
        "                    regularizer, trainable, name=''):   \n",
        "        kernel = self.make_var('weights'+name, [k_h, k_w, c_i, c_o], init_weights, regularizer, trainable) \n",
        "        biases = self.make_var('biases'+name, [c_o], init_biases, None, trainable)\n",
        "        tf.summary.histogram('w', kernel)\n",
        "        tf.summary.histogram('b', biases)\n",
        "        \n",
        "        wx = convolve(input, kernel)\n",
        "        a = activate(tf.nn.bias_add(wx, biases))\n",
        "        a = tf.contrib.layers.instance_norm(a, center=False, scale=False)\n",
        "        return a\n",
        "    \n",
        "    \n",
        "    def l2_regularizer(self, weight_decay=0.0005, scope=None):\n",
        "        def regularizer(tensor):\n",
        "            with tf.name_scope(scope, default_name='l2_regularizer', values=[tensor]):\n",
        "                factor = tf.convert_to_tensor(weight_decay, name='weight_decay')\n",
        "                return tf.multiply(factor, tf.nn.l2_loss(tensor), name='decayed_value')\n",
        "        return regularizer\n",
        "    \n",
        "    \n",
        "    def make_var(self, name, shape, initializer=None, regularizer=None, trainable=True):\n",
        "        return tf.compat.v1.get_variable(name, shape, initializer=initializer, regularizer=regularizer, trainable=trainable)      \n",
        "    \n",
        "    \n",
        "    def feed(self, *args):\n",
        "        assert len(args) != 0\n",
        "        \n",
        "        self.layer_inputs = []\n",
        "        for layer in args:\n",
        "            if isinstance(layer, str):\n",
        "                try:\n",
        "                    layer = self.layers[layer]\n",
        "                    print(layer)\n",
        "                except KeyError:\n",
        "                    print(list(self.layers.keys()))\n",
        "                    raise KeyError('Unknown layer name fed: %s' % layer)\n",
        "            self.layer_inputs.append(layer)\n",
        "        return self\n",
        "        \n",
        "        \n",
        "    def get_output(self, layer):\n",
        "        try:\n",
        "            layer = self.layers[layer]\n",
        "        except KeyError:\n",
        "            print(list(self.layers.keys()))\n",
        "            raise KeyError('Unknown layer name fed: %s' % layer)\n",
        "        return layer\n",
        "        \n",
        "        \n",
        "    def get_unique_name(self, prefix):\n",
        "        id = sum(t.startswith(prefix) for t,_ in list(self.layers.items())) + 1\n",
        "        return '%s_%d' % (prefix, id)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZsXtJr-KyLu"
      },
      "source": [
        "class CUTIE(Model):\n",
        "    \"\"\" Set up model framework\n",
        "    \"\"\"\n",
        "    def __init__(self, num_vocabs, num_classes, params, trainable=True):\n",
        "        self.name = \"CUTIE_benchmark\"\n",
        "        \n",
        "        self.data = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None, 1], name='grid_table')\n",
        "        self.gt_classes = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None], name='gt_classes')\n",
        "        self.use_ghm = tf.equal(1, params.use_ghm) if hasattr(params, 'use_ghm') else tf.equal(1, 0) #params.use_ghm \n",
        "        self.activation = 'sigmoid' if (hasattr(params, 'use_ghm') and params.use_ghm) else 'relu'\n",
        "        self.ghm_weights = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, num_classes], name='ghm_weights')        \n",
        "        self.layers = dict({'data': self.data, 'gt_classes': self.gt_classes, 'ghm_weights': self.ghm_weights}) \n",
        "         \n",
        "        self.num_vocabs = num_vocabs\n",
        "        self.num_classes = num_classes     \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.embedding_size = params.embedding_size\n",
        "        self.weight_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
        "        self.hard_negative_ratio = params.hard_negative_ratio if hasattr(params, 'hard_negative_ratio') else 0.0\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "        \n",
        "    \n",
        "    def setup(self):        \n",
        "        # Input\n",
        "        (self.feed('data')\n",
        "             .embed(self.num_vocabs, self.embedding_size, name='embedding'))  \n",
        "        \n",
        "        # Encoder\n",
        "        (self.feed('embedding')\n",
        "             .conv(3, 5, 64, 1, 1, name='encoder1_1')\n",
        "             .conv(3, 5, 128, 1, 1, name='encoder1_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool1')\n",
        "             .conv(3, 5, 128, 1, 1, name='encoder2_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder2_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool2')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder3_1')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder3_2')\n",
        "             .max_pool(2, 2, 2, 2, name='pool3')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder4_1')\n",
        "             .conv(3, 5, 512, 1, 1, name='encoder4_2'))\n",
        "        \n",
        "        # Decoder\n",
        "        (self.feed('encoder4_2')\n",
        "             .up_conv(3, 5, 512, 1, 1, name='up1')\n",
        "             .conv(3, 5, 256, 1, 1, name='decoder1_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='decoder1_2')\n",
        "             .up_conv(3, 5, 256, 1, 1, name='up2')\n",
        "             .conv(3, 5, 128, 1, 1, name='decoder2_1')\n",
        "             .conv(3, 5, 128, 1, 1, name='decoder2_2')\n",
        "             .up_conv(3, 5, 128, 1, 1, name='up3')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder3_1')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder3_2'))\n",
        "        \n",
        "        # Classification\n",
        "        (self.feed('decoder3_2')\n",
        "             .conv(1, 1, self.num_classes, 1, 1, activation=self.activation, name='cls_logits')\n",
        "             .softmax(name='softmax'))  \n",
        "\n",
        "        \n",
        "    def build_loss(self):\n",
        "        labels = self.get_output('gt_classes')\n",
        "        cls_logits = self.get_output('cls_logits')         \n",
        "        cls_logits = tf.cond(self.use_ghm, lambda: cls_logits*self.get_output('ghm_weights'), \n",
        "                             lambda: cls_logits, name=\"GradientHarmonizingMechanism\")      \n",
        "        \n",
        "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=cls_logits)\n",
        "            \n",
        "        with tf.compat.v1.variable_scope('HardNegativeMining'):\n",
        "            labels = tf.reshape(labels, [-1])  \n",
        "            cross_entropy = tf.reshape(cross_entropy, [-1])\n",
        "            \n",
        "            fg_idx = tf.where(tf.not_equal(labels, 0))\n",
        "            fgs = tf.gather(cross_entropy, fg_idx)\n",
        "            bg_idx = tf.where(tf.equal(labels, 0))\n",
        "            bgs = tf.gather(cross_entropy, bg_idx)\n",
        "             \n",
        "            num = self.hard_negative_ratio * tf.shape(fgs)[0]\n",
        "            num_bg = tf.cond(tf.shape(bgs)[0]<num, lambda:tf.shape(bgs)[0], lambda:num)\n",
        "            sorted_bgs, _ = tf.nn.top_k(tf.transpose(bgs), num_bg, sorted=True)\n",
        "            cross_entropy = fgs + sorted_bgs\n",
        "        \n",
        "        # Total loss\n",
        "        model_loss = tf.reduce_mean(cross_entropy)\n",
        "        regularization_loss = tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES), name='regularization')\n",
        "        total_loss = model_loss + regularization_loss\n",
        "        \n",
        "        tf.summary.scalar('model_loss', model_loss)\n",
        "        tf.summary.scalar('regularization_loss', regularization_loss)\n",
        "        tf.summary.scalar('total_loss', total_loss)\n",
        "        \n",
        "        logits = self.get_output('cls_logits')\n",
        "        softmax_logits = self.get_output('softmax') #cls_logits\n",
        "        return model_loss, regularization_loss, total_loss, logits, softmax_logits"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGsw6HsaL2SL"
      },
      "source": [
        "class CUTIERes(CUTIE):\n",
        "    \"\"\" Set up CUTIE-B model\n",
        "    \"\"\"\n",
        "    def __init__(self, num_vocabs, num_classes, params, trainable=True):\n",
        "        self.name = \"CUTIE_atrousSPP\"\n",
        "        \n",
        "        self.data_grid = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None, 1], name='data_grid')\n",
        "        self.gt_classes = tf.compat.v1.placeholder(tf.int32, shape=[None, None, None], name='gt_classes') \n",
        "        self.data_image = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3], name='data_image') \n",
        "        self.ps_1d_indices = tf.compat.v1.placeholder(tf.int32, shape=[None, None], name='ps_1d_indices') \n",
        "        \n",
        "        self.use_ghm = tf.equal(1, params.use_ghm) if hasattr(params, 'use_ghm') else tf.equal(1, 0) \n",
        "        self.activation = 'sigmoid' if (hasattr(params, 'use_ghm') and params.use_ghm) else 'relu'\n",
        "        self.dropout = params.data_augmentation_dropout if hasattr(params, 'data_augmentation_dropout') else 1\n",
        "        self.ghm_weights = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, num_classes], name='ghm_weights')        \n",
        "        self.layers = dict({'data_grid': self.data_grid, 'gt_classes': self.gt_classes, 'ghm_weights':self.ghm_weights})\n",
        "\n",
        "        self.num_vocabs = num_vocabs\n",
        "        self.num_classes = num_classes     \n",
        "        self.trainable = trainable\n",
        "        \n",
        "        self.embedding_size = params.embedding_size\n",
        "        self.weight_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
        "        self.hard_negative_ratio = params.hard_negative_ratio if hasattr(params, 'hard_negative_ratio') else 0.0\n",
        "        \n",
        "        self.layer_inputs = []        \n",
        "        self.setup()\n",
        "        \n",
        "    \n",
        "    def setup(self):        \n",
        "        # Input\n",
        "        (self.feed('data_grid')\n",
        "             .embed(self.num_vocabs, self.embedding_size, name='embedding', dropout=self.dropout))  \n",
        "        \n",
        "        # Encoder\n",
        "        (self.feed('embedding')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_1')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_2')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_3')\n",
        "             .conv(3, 5, 256, 1, 1, name='encoder1_4')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 2, name='encoder1_5')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 4, name='encoder1_6')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 8, name='encoder1_7')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 16, name='encoder1_8'))\n",
        "        \n",
        "        # Atrous Spatial Pyramid Pooling module\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 4, name='aspp_1'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 8, name='aspp_2'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .dilate_conv(3, 5, 256, 1, 1, 16, name='aspp_3'))\n",
        "        (self.feed('encoder1_8')\n",
        "             .global_pool(name='aspp_4'))\n",
        "        (self.feed('aspp_1', 'aspp_2', 'aspp_3', 'aspp_4')\n",
        "             .concat(3, name='aspp_concat')\n",
        "             .conv(1, 1, 256, 1, 1, name='aspp_1x1'))\n",
        "        \n",
        "        # Combine low level features\n",
        "        (self.feed('encoder1_1', 'aspp_1x1')\n",
        "             .concat(3, name='concat1')\n",
        "             .conv(3, 5, 64, 1, 1, name='decoder1_1'))\n",
        "        \n",
        "        # Classification\n",
        "        (self.feed('decoder1_1') \n",
        "             .conv(1, 1, self.num_classes, 1, 1, activation=self.activation, name='cls_logits') # sigmoid for ghm\n",
        "             .softmax(name='softmax'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xfB_lstL_nh"
      },
      "source": [
        "# 2. Predict Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kke4HoK2L4F2"
      },
      "source": [
        "### Parse arguments needed for the model\n",
        "parser = argparse.ArgumentParser(description='CUTIE parameters')\n",
        "\n",
        "# Dummy parser arguments for notebook\n",
        "parser.add_argument('-f')\n",
        "\n",
        "# Data\n",
        "parser.add_argument('--use_cutie2', type=bool, default=False) # True to read image from doc_path \n",
        "parser.add_argument('--is_table', type=bool, default=False) # True to read image from doc_path \n",
        "parser.add_argument('--doc_path', type=str, default='ExpressExpenseJsonPredict')\n",
        "parser.add_argument('--save_prefix', type=str, default='ExpressExpense', help='prefix for load ckpt model') # Save log/models with prefix\n",
        "\n",
        "# Checkpoint\n",
        "parser.add_argument('--e_ckpt_path', type=str, default='checkpoint/')\n",
        "parser.add_argument('--ckpt_file', type=str, default='CUTIE_atrousSPP_d20000c2(r80c80)_iter_200.ckpt')\n",
        "parser.add_argument('--rows_target', type=int, default=80)  \n",
        "parser.add_argument('--cols_target', type=int, default=80)  \n",
        "parser.add_argument('--rows_ulimit', type=int, default=80) \n",
        "parser.add_argument('--cols_ulimit', type=int, default=80) \n",
        "parser.add_argument('--restore_ckpt', type=bool, default=True)\n",
        "\n",
        "# Dict\n",
        "parser.add_argument('--load_dict', type=bool, default=True, help='True to work based on an existing dict') \n",
        "parser.add_argument('--load_dict_from_path', type=str, default='dict/')\n",
        " \n",
        "# Model\n",
        "parser.add_argument('--embedding_size', type=int, default=128)\n",
        "\n",
        "# Inference\n",
        "parser.add_argument('--c_threshold', type=float, default=0.5) \n",
        "\n",
        "params = parser.parse_args()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh0Vu_HxMCGK",
        "outputId": "29280eda-4997-4c78-e7a8-7d91476b0ed8"
      },
      "source": [
        "# Call DataLoader to get basic information to capture total amount on receipts\n",
        "data_loader = DataLoader(params, update_dict=False, load_dictionary=True, data_split=0.75) \n",
        "num_words = max(20000, data_loader.num_words)\n",
        "num_classes = data_loader.num_classes\n",
        "\n",
        "# Initilize the CUTIE-B model\n",
        "network = CUTIERes(num_words, num_classes, params)\n",
        "model_output = network.get_output('softmax')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"data_grid:0\", shape=(?, ?, ?, 1), dtype=int32)\n",
            "WARNING:tensorflow:From <ipython-input-7-41ff73dc077a>:48: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"embedding/Reshape_1:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_8/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_2/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_3/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"ResizeNearestNeighbor:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"encoder1_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"aspp_1x1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
            "Tensor(\"decoder1_1/InstanceNorm/instancenorm/add_1:0\", shape=(?, ?, ?, 64), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np6dshtNMEaR",
        "outputId": "e3393d56-4b63-45b6-c511-cbed654740c2"
      },
      "source": [
        "# Use the trained model to capture total amount on receipt\n",
        "ckpt_saver = tf.train.Saver()\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    try:\n",
        "        ckpt_path = join(params.e_ckpt_path, params.save_prefix, params.ckpt_file)\n",
        "        ckpt = tf.train.get_checkpoint_state(ckpt_path)\n",
        "        print('Restoring from {}...'.format(ckpt_path))\n",
        "        ckpt_saver.restore(sess, ckpt_path)\n",
        "        print('{} restored'.format(ckpt_path))\n",
        "    except:\n",
        "        raise Exception('Check your pretrained {:s}'.format(ckpt_path))\n",
        "    \n",
        "    # Calculate validation accuracy and display results   \n",
        "    recalls, accs_strict, accs_soft = [], [], []\n",
        "    num_test = len(data_loader.validation_docs)\n",
        "    for i in range(num_test):\n",
        "        data = data_loader.fetch_validation_data()\n",
        "        print('{:d} samples left to be tested'.format(num_test-i))\n",
        "        \n",
        "        feed_dict = {\n",
        "            network.data_grid: data['grid_table'],\n",
        "        }\n",
        "        if params.use_cutie2:\n",
        "            feed_dict = {\n",
        "                network.data_grid: data['grid_table'],\n",
        "                network.data_image: data['data_image'],\n",
        "                network.ps_1d_indices: data['ps_1d_indices']\n",
        "            }\n",
        "        fetches = [model_output]\n",
        "        \n",
        "        print(data['file_name'][0])\n",
        "        print(data['grid_table'].shape, data['data_image'].shape, data['ps_1d_indices'].shape)\n",
        "        \n",
        "        timer_start = timeit.default_timer()\n",
        "        [model_output_val] = sess.run(fetches=fetches, feed_dict=feed_dict)\n",
        "        timer_stop = timeit.default_timer()\n",
        "        print('\\t >>time per step: %.2fs <<'%(timer_stop - timer_start))\n",
        "            \n",
        "        if not params.is_table:\n",
        "            recall, acc_strict, acc_soft, res = cal_accuracy(params.c_threshold, data_loader, np.array(data['grid_table']), \n",
        "                                                    np.array(data['gt_classes']), model_output_val, \n",
        "                                                    np.array(data['label_mapids']), data['bbox_mapids'])  \n",
        "        else:\n",
        "            recall, acc_strict, acc_soft, res = cal_accuracy_table(params.c_threshold, data_loader, np.array(data['grid_table']), \n",
        "                                                    np.array(data['gt_classes']), model_output_val, \n",
        "                                                    np.array(data['label_mapids']), data['bbox_mapids'])\n",
        "        recalls += [recall]\n",
        "        accs_strict += [acc_strict] \n",
        "        accs_soft += [acc_soft]\n",
        "        if acc_strict != 1:\n",
        "            # Show res for current batch\n",
        "            print(res.decode()) \n",
        "        \n",
        "        # Visualize result\n",
        "        shape = data['shape']\n",
        "        # Use one single file_name\n",
        "        file_name = data['file_name'][0] \n",
        "        bboxes = data['bboxes'][file_name]\n",
        "        if not params.is_table:\n",
        "            vis_bbox(data_loader, params.doc_path, np.array(data['grid_table'])[0], \n",
        "                      np.array(data['gt_classes'])[0], np.array(model_output_val)[0], file_name, \n",
        "                      np.array(bboxes), shape)\n",
        "        else:\n",
        "            vis_table(data_loader, params.doc_path, np.array(data['grid_table'])[0], \n",
        "                      np.array(data['gt_classes'])[0], np.array(model_output_val)[0], file_name, \n",
        "                      np.array(bboxes), shape)\n",
        "\n",
        "    recall = sum(recalls) / len(recalls)\n",
        "    acc_strict = sum(accs_strict) / len(accs_strict)\n",
        "    acc_soft = sum(accs_soft) / len(accs_soft)\n",
        "    print('EVALUATION ACC (Recall/Acc): %.3f / %.3f (%.3f) \\n'%(recall, acc_strict, acc_soft))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restoring from checkpoint/ExpressExpense/CUTIE_atrousSPP_d20000c2(r80c80)_iter_200.ckpt...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/ExpressExpense/CUTIE_atrousSPP_d20000c2(r80c80)_iter_200.ckpt\n",
            "checkpoint/ExpressExpense/CUTIE_atrousSPP_d20000c2(r80c80)_iter_200.ckpt restored\n",
            "1 samples left to be tested\n",
            "1154-receipt.jpg\n",
            "(1, 80, 80, 1) (0,) (0,)\n",
            "\t >>time per step: 2.55s <<\n",
            "len(data_input_flat): 6400\n",
            "indexes: [ 104  111  122  268  277  285  424  435  442  450  510  601  706  742\n",
            "  777  809 1027 1047 1055 1063 1100 1128 1180 1217 1426 1444 1449 1456\n",
            " 1466 1611 1621 1683 1746 1773 1785 1843 1853 1906 2003 2011 2066 2163\n",
            " 2170 2177 2183 2193 2226 2323 2330 2339 2386 2491 2501 2649 2788 2802\n",
            " 2806 2811 2824 2966 2972 2983 3108 3122 3130 3141 3281 3288 3295 3303\n",
            " 3348 3445 3457 3516 3763 3773 3828 3922 3929 3989 4082 4088 4150 4495\n",
            " 4549 4567 4971 5717 6108 6123 6145 6349 6361]\n",
            "\n",
            "TTL(GT/Inf):\t\"[UNK] [UNK]\" | \"[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\"\n",
            " \t FALSES =>> \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O,  \"[UNK]\"/O, \n",
            "EVALUATION ACC (Recall/Acc): 1.000 / 0.000 (1.000) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQAQb8MUNNyq"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}